{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a651605e-4c17-4d4c-99de-a40ab10ac6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\brand\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\brand\\anaconda3\\lib\\site-packages (10.3.0)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\brand\\anaconda3\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: comtypes in c:\\users\\brand\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.8)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\brand\\anaconda3\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\brand\\anaconda3\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from opencv-python-headless) (1.26.4)\n",
      "Requirement already satisfied: comtypes in c:\\users\\brand\\anaconda3\\lib\\site-packages (from pyttsx3) (1.4.8)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\brand\\anaconda3\\lib\\site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install pillow\n",
    "!pip install pyttsx3\n",
    "!pip install opencv-python-headless pyttsx3\n",
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f674fe56-89a1-410d-8e2a-324f021c2f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\brand\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\brand\\anaconda3\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\brand\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: pygame in c:\\users\\brand\\anaconda3\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\brand\\anaconda3\\lib\\site-packages (8.3.48)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (3.8.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (2.5.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.13)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\brand\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\brand\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install pygame\n",
    "!pip install ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc67712-45ea-4eda-9864-8f9fde5c0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original sin modificaciones, se demora la parte de la deteccion de objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "932485dc-d3be-4a48-a032-a652d4e60523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        # Variables de estado\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = {}\n",
    "\n",
    "        # Cargar el modelo de detección de objetos (YOLO)\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        # Crear interfaz\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Frame para el video y los controles\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        # Frame para el historial\n",
    "        self.frame_historial = tk.Frame(self.frame_principal, bg=\"#2e2e2e\", width=300)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        # Mostrar logo\n",
    "        self.logo_imagen_tk = None  # Declarar la variable a nivel de instancia\n",
    "        self.cargar_logo()\n",
    "\n",
    "        # Botones\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        # Crear canvas para video\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        # Etiquetas para el historial\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.label_historial = tk.Label(self.frame_historial, text=\"\", bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                        anchor=\"nw\", justify=\"left\")\n",
    "        self.label_historial.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        \"\"\"Abre la cámara y comienza a capturar el video.\"\"\"\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "\n",
    "            # Registrar en el historial que la cámara ha sido abierta\n",
    "            self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = \"Cámara abierta\"\n",
    "            self.actualizar_historial()\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        \"\"\"Captura el video y actualiza la imagen en el canvas de Tkinter.\"\"\"\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                # Realizar detección de objetos\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                objetos_detectados = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.5:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "                            objetos_detectados.append(self.classes[class_id])\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.classes[class_ids[i]])\n",
    "                        color = (0, 255, 0)\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "                # Anunciar objetos detectados\n",
    "                if objetos_detectados:\n",
    "                    self.engine.say(\", \".join(set(objetos_detectados)))  # Decir los objetos detectados\n",
    "                    self.engine.runAndWait()\n",
    "\n",
    "                # Actualizar historial con los objetos detectados\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                self.historial_detecciones[timestamp] = f\"Objetos detectados: {', '.join(set(objetos_detectados))}\"\n",
    "                self.actualizar_historial()\n",
    "\n",
    "            # Mostrar el frame en el canvas\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        \"\"\"Cierra la cámara y detiene la captura de video.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            self.cap.release()\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "\n",
    "            # Registrar en el historial que la cámara ha sido cerrada\n",
    "            self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = \"Cámara cerrada\"\n",
    "            self.actualizar_historial()\n",
    "\n",
    "            if self.thread is not None:\n",
    "                self.thread.join()\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        \"\"\"Toma una foto y la guarda.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.historial_detecciones[timestamp] = \"Foto tomada\"\n",
    "                self.actualizar_historial()\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        \"\"\"Inicia o detiene la grabación de video.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.historial_detecciones[timestamp] = \"Grabación de video iniciada\"\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.historial_detecciones[timestamp] = \"Grabación de video detenida\"\n",
    "                self.actualizar_historial()\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        \"\"\"Activa o desactiva la detección de objetos.\"\"\"\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = f\"Detección de objetos {estado}\"\n",
    "        self.actualizar_historial()\n",
    "\n",
    "    def actualizar_historial(self):\n",
    "        \"\"\"Actualiza el historial mostrado en la interfaz.\"\"\"\n",
    "        historial_texto = \"\\n\".join([f\"{hora}: {accion}\" for hora, accion in self.historial_detecciones.items()])\n",
    "        self.label_historial.config(text=historial_texto)\n",
    "\n",
    "    def salir(self):\n",
    "        \"\"\"Cierra la aplicación.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            self.cerrar_camara()\n",
    "        self.root.quit()\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013fda5e-ca54-461c-b89c-0217b5c30f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modificacion del codigo base se mejora el rendimiento, se ajusta la voz para que anuncie las respuestas en un intervalo de 1 segundo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b4132ce-d6d4-4322-a88f-fcae7295c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        # Variables de estado\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = {}\n",
    "        self.objetos_para_anunciar = set()\n",
    "\n",
    "        # Cargar el modelo de detección de objetos (YOLO)\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        # Crear interfaz\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Frame para el video y los controles\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        # Frame para el historial\n",
    "        self.frame_historial = tk.Frame(self.frame_principal, bg=\"#2e2e2e\", width=300)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        # Mostrar logo\n",
    "        self.logo_imagen_tk = None  # Declarar la variable a nivel de instancia\n",
    "        self.cargar_logo()\n",
    "\n",
    "        # Botones\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        # Crear canvas para video\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        # Etiquetas para el historial\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.label_historial = tk.Label(self.frame_historial, text=\"\", bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                        anchor=\"nw\", justify=\"left\")\n",
    "        self.label_historial.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        \"\"\"Abre la cámara y comienza a capturar el video.\"\"\"\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "\n",
    "            # Registrar en el historial que la cámara ha sido abierta\n",
    "            self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = \"Cámara abierta\"\n",
    "            self.actualizar_historial()\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            # Hilo para anunciar objetos detectados\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        \"\"\"Captura el video y actualiza la imagen en el canvas de Tkinter.\"\"\"\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                # Realizar detección de objetos\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.6:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.classes[class_ids[i]])\n",
    "                        color = (0, 255, 0)\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                        self.objetos_para_anunciar.add(label)\n",
    "\n",
    "                # Actualizar historial con los objetos detectados\n",
    "                if self.objetos_para_anunciar:\n",
    "                    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    objetos_detectados = \", \".join(self.objetos_para_anunciar)\n",
    "                    self.historial_detecciones[timestamp] = f\"Objetos detectados: {objetos_detectados}\"\n",
    "                    self.actualizar_historial()\n",
    "\n",
    "            # Mostrar el frame en el canvas\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        \"\"\"Pronuncia los objetos detectados en intervalos regulares.\"\"\"\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)  # Intervalo entre anuncios\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        \"\"\"Cierra la cámara y detiene la captura de video.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            self.cap.release()\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "\n",
    "            # Registrar en el historial que la cámara ha sido cerrada\n",
    "            self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = \"Cámara cerrada\"\n",
    "            self.actualizar_historial()\n",
    "\n",
    "            if self.thread is not None:\n",
    "                self.thread.join()\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        \"\"\"Toma una foto y la guarda.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.historial_detecciones[timestamp] = \"Foto tomada\"\n",
    "                self.actualizar_historial()\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        \"\"\"Inicia o detiene la grabación de video.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.historial_detecciones[timestamp] = \"Grabación de video iniciada\"\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.historial_detecciones[timestamp] = \"Grabación de video detenida\"\n",
    "                self.actualizar_historial()\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        \"\"\"Activa o desactiva la detección de objetos.\"\"\"\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = f\"Detección de objetos {estado}\"\n",
    "        self.actualizar_historial()\n",
    "\n",
    "    def actualizar_historial(self):\n",
    "        \"\"\"Actualiza el historial mostrado en la interfaz.\"\"\"\n",
    "        historial_texto = \"\\n\".join([f\"{hora}: {accion}\" for hora, accion in self.historial_detecciones.items()])\n",
    "        self.label_historial.config(text=historial_texto)\n",
    "        time.sleep(1)\n",
    "    def salir(self):\n",
    "        \"\"\"Cierra la aplicación.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            self.cerrar_camara()\n",
    "        self.root.quit()\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41498379-661f-4e63-95e6-2103fc5e1ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codigo con la modificacion final para  la seguridad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f8c007-e2a9-4a75-8c57-e46f22dbea25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame  # Importa pygame para la reproducción de audio\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        # Inicializar Pygame para el audio\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        # Variables de estado\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = {}\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0  # Para gestionar el tiempo de alerta\n",
    "\n",
    "        # Cargar el modelo de detección de objetos (YOLO)\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        # Crear interfaz\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        # Frame para el video y los controles\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        # Frame para el historial\n",
    "        self.frame_historial = tk.Frame(self.frame_principal, bg=\"#2e2e2e\", width=300)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        # Mostrar logo\n",
    "        self.logo_imagen_tk = None\n",
    "        self.cargar_logo()\n",
    "\n",
    "        # Botones\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        # Crear canvas para video\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        # Etiquetas para el historial\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.label_historial = tk.Label(self.frame_historial, text=\"\", bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                        anchor=\"nw\", justify=\"left\")\n",
    "        self.label_historial.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        \"\"\"Abre la cámara y comienza a capturar el video.\"\"\"\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "\n",
    "            # Registrar en el historial que la cámara ha sido abierta\n",
    "            self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = \"Cámara abierta\"\n",
    "            self.actualizar_historial()\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            # Hilo para anunciar objetos detectados\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        \"\"\"Captura el video y actualiza la imagen en el canvas de Tkinter.\"\"\"\n",
    "        frame_count = 0  # Contador de frames\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if self.detectando_objetos and frame_count % 3 == 0:  # Procesar cada 3 frames\n",
    "                # Realizar detección de objetos\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.6:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.classes[class_ids[i]])\n",
    "                        color = (0, 255, 0)\n",
    "                        # Verificar si el objeto es un arma\n",
    "                        if label in [\"knife\", \"pistol\"]:  # Ajusta estos nombres según tu archivo coco.names\n",
    "                            color = (255, 0, 0)  # Contorno rojo\n",
    "                            current_time = time.time()\n",
    "                            if current_time - self.last_alert_time > 3:  # Reproducir sonido cada 3 segundos\n",
    "                                self.reproducir_alerta()  # Llama a la función de reproducción de audio\n",
    "                                self.last_alert_time = current_time\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                        self.objetos_para_anunciar.add(label)\n",
    "\n",
    "                # Actualizar historial con los objetos detectados\n",
    "                if self.objetos_para_anunciar:\n",
    "                    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    objetos_detectados = \", \".join(self.objetos_para_anunciar)\n",
    "                    self.historial_detecciones[timestamp] = f\"Objetos detectados: {objetos_detectados}\"\n",
    "                    self.actualizar_historial()\n",
    "\n",
    "            # Mostrar el frame en el canvas\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "            frame_count += 1  # Incrementar el contador de frames\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        \"\"\"Pronuncia los objetos detectados en intervalos regulares.\"\"\"\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)  # Intervalo entre anuncios\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        \"\"\"Cierra la cámara y detiene la captura de video.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            self.cap.release()\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "\n",
    "            # Registrar en el historial que la cámara ha sido cerrada\n",
    "            self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = \"Cámara cerrada\"\n",
    "            self.actualizar_historial()\n",
    "\n",
    "            if self.thread is not None:\n",
    "                self.thread.join()\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        \"\"\"Toma una foto y la guarda.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.historial_detecciones[timestamp] = \"Foto tomada\"\n",
    "                self.actualizar_historial()\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        \"\"\"Inicia o detiene la grabación de video.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.historial_detecciones[timestamp] = \"Grabación de video iniciada\"\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.historial_detecciones[timestamp] = \"Grabación de video detenida\"\n",
    "                self.actualizar_historial()\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        \"\"\"Activa o desactiva la detección de objetos.\"\"\"\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = f\"Detección de objetos {estado}\"\n",
    "        self.actualizar_historial()\n",
    "\n",
    "    def actualizar_historial(self):\n",
    "        \"\"\"Actualiza el historial mostrado en la interfaz.\"\"\"\n",
    "        historial_texto = \"\\n\".join([f\"{hora}: {accion}\" for hora, accion in self.historial_detecciones.items()])\n",
    "        self.label_historial.config(text=historial_texto)\n",
    "        time.sleep(1)\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        \"\"\"Reproduce el sonido de alerta.\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def salir(self):\n",
    "        \"\"\"Cierra la aplicación.\"\"\"\n",
    "        if self.camara_activa:\n",
    "            self.cerrar_camara()\n",
    "        self.root.quit()\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda60741-0b56-4e8d-8295-e881f22780c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se mejora el codigo para generar mejores reportes y se mejora la funcion del historial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7134c7-f25c-42b0-8f8f-3cc426113896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = {}\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True  # Estado de la voz\n",
    "        self.alarma_activar = True  # Estado de la alarma\n",
    "\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.frame_historial = tk.Frame(self.frame_principal, bg=\"#2e2e2e\", width=300)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.logo_imagen_tk = None\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.label_historial = tk.Label(self.frame_historial, text=\"\", bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                        anchor=\"nw\", justify=\"left\")\n",
    "        self.label_historial.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "\n",
    "            self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = \"Cámara abierta\"\n",
    "            self.actualizar_historial()\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        frame_count = 0\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if self.detectando_objetos and frame_count % 3 == 0:\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.6:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.classes[class_ids[i]])\n",
    "                        color = (0, 255, 0)\n",
    "                        if label in [\"knife\", \"pistol\"]:\n",
    "                            color = (255, 0, 0)\n",
    "                            current_time = time.time()\n",
    "                            if self.alarma_activar and (current_time - self.last_alert_time > 3):\n",
    "                                self.reproducir_alerta()\n",
    "                                self.last_alert_time = current_time\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                        self.objetos_para_anunciar.add(label)\n",
    "\n",
    "                if self.objetos_para_anunciar:\n",
    "                    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    objetos_detectados = \", \".join(self.objetos_para_anunciar)\n",
    "                    self.historial_detecciones[timestamp] = f\"Objetos detectados: {objetos_detectados}\"\n",
    "                    self.actualizar_historial()\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "            frame_count += 1\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar and self.voz_activar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            self.cap.release()\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "\n",
    "            self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = \"Cámara cerrada\"\n",
    "            self.actualizar_historial()\n",
    "\n",
    "            if self.thread is not None:\n",
    "                self.thread.join()\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.historial_detecciones[timestamp] = \"Foto tomada\"\n",
    "                self.actualizar_historial()\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.historial_detecciones[timestamp] = \"Grabación de video iniciada\"\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.historial_detecciones[timestamp] = \"Grabación de video detenida\"\n",
    "                self.actualizar_historial()\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = f\"Detección de objetos {estado}\"\n",
    "        self.actualizar_historial()\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.boton_voz.config(text=f\"{estado.capitalize()} Voz\")\n",
    "        self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = f\"Voz {estado}\"\n",
    "        self.actualizar_historial()\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.boton_alarma.config(text=f\"{estado.capitalize()} Alarma\")\n",
    "        self.historial_detecciones[datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")] = f\"Alarma {estado}\"\n",
    "        self.actualizar_historial()\n",
    "\n",
    "    def actualizar_historial(self):\n",
    "        historial_texto = \"\\n\".join([f\"{hora}: {accion}\" for hora, accion in self.historial_detecciones.items()])\n",
    "        self.label_historial.config(text=historial_texto)\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def salir(self):\n",
    "        if self.camara_activa:\n",
    "            self.cerrar_camara()\n",
    "        self.root.quit()\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72889e90-e330-4ba1-b0ec-aebdaf7e14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se arregla la funcionalidad del sistema con el boton de cerrar camara y se mejora el tema del rendimieto y el historial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a99810-9a29-45c7-bddb-3cec196d42f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6 (anunciar_objetos_detectados):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\brand\\anaconda3\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\brand\\anaconda3\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\brand\\AppData\\Local\\Temp\\ipykernel_5372\\1174535221.py\", line 215, in anunciar_objetos_detectados\n",
      "  File \"C:\\Users\\brand\\anaconda3\\Lib\\site-packages\\pyttsx3\\engine.py\", line 180, in runAndWait\n",
      "    raise RuntimeError('run loop already started')\n",
      "RuntimeError: run loop already started\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.logo_imagen_tk = None\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Descargar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            objetos_detectados = set()  # Para almacenar objetos detectados\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                # Prepara la imagen para la detección\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.6:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.classes[class_ids[i]])\n",
    "                        objetos_detectados.add(label)  # Agregar a la lista de objetos detectados\n",
    "                        color = (0, 255, 0)  # Verde por defecto\n",
    "                        if label in [\"knife\", \"pistol\"]:  # Cambiar a rojo si es un objeto peligroso\n",
    "                            color = (255, 0, 0)  # Rojo para objetos peligrosos\n",
    "                            current_time = time.time()\n",
    "                            if self.alarma_activar and (current_time - self.last_alert_time > 3):\n",
    "                                self.reproducir_alerta()\n",
    "                                self.last_alert_time = current_time\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Actualizar el historial de objetos detectados\n",
    "            if objetos_detectados:\n",
    "                self.agregar_historial(f\"Objetos detectados: {', '.join(objetos_detectados)}\")\n",
    "                self.objetos_para_anunciar.update(objetos_detectados)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar and self.voz_activar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            # Detener el hilo de video\n",
    "            if self.thread is not None:\n",
    "                self.thread.join(timeout=1)  # Espera un segundo para que el hilo termine\n",
    "            \n",
    "            # Liberar la cámara\n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            # Actualizar el estado de los botones\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.agregar_historial(\"Foto tomada\")\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.agregar_historial(\"Grabación de video iniciada\")\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.agregar_historial(\"Grabación de video detenida\")\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.boton_voz.config(text=f\"{estado.capitalize()} Voz\")\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.boton_alarma.config(text=f\"{estado.capitalize()} Alarma\")\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        if len(self.historial_detecciones) > 50:  # Limitar el tamaño del historial\n",
    "            self.historial_detecciones.pop(0)\n",
    "        \n",
    "        # Actualizar el historial en el Text\n",
    "        self.text_historial.config(state=tk.NORMAL)  # Habilitar el Text para la edición\n",
    "        self.text_historial.delete(1.0, tk.END)  # Limpiar el Text\n",
    "        self.text_historial.insert(tk.END, \"\\n\".join(self.historial_detecciones))  # Agregar nuevo texto\n",
    "        self.text_historial.config(state=tk.DISABLED)  # Deshabilitar el Text para evitar ediciones\n",
    "        self.text_historial.yview_moveto(1)  # Desplazar hacia abajo\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        archivo = filedialog.asksaveasfile(defaultextension=\".txt\", filetypes=[(\"Text files\", \"*.txt\")])\n",
    "        if archivo:\n",
    "            for entrada in self.historial_detecciones:\n",
    "                archivo.write(entrada + \"\\n\")\n",
    "            archivo.close()\n",
    "            messagebox.showinfo(\"Éxito\", \"Historial descargado correctamente.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()  # Asegurarse de que se cierre la cámara\n",
    "        self.root.quit()  # Cerrar la aplicación\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b156fb-0e3a-418d-b7d1-d5d0a3e65a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# El codigo finiquitado al 100% con tutorial incluido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d676ed9-64e1-45fb-96f2-ff63efd73c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.logo_imagen_tk = None\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Descargar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.mostrar_tutorial()\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def mostrar_tutorial(self):\n",
    "        self.tutorial = tk.Toplevel(self.root)\n",
    "        self.tutorial.title(\"Tutorial\")\n",
    "        self.tutorial.geometry(\"400x300\")\n",
    "        self.tutorial.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        tutorial_text = \"\"\"\n",
    "        Bienvenido a la aplicación de detección de imágenes.\n",
    "        \n",
    "        1. Abrir Cámara: Inicia la cámara para la detección.\n",
    "        2. Detectar Objetos: Activa la detección de objetos en la cámara.\n",
    "        3. Tomar Foto: Captura una imagen de la cámara.\n",
    "        4. Grabar Video: Inicia o detiene la grabación de video.\n",
    "        5. Descargar Historial: Guarda el historial de detecciones en un archivo.\n",
    "        6. Activar Voz: Anuncia los objetos detectados.\n",
    "        7. Activar Alarma: Reproduce una alarma si se detectan objetos peligrosos.\n",
    "        8. Salir: Cierra la aplicación.\n",
    "\n",
    "        Presiona 'Saltar Tutorial' para omitir este tutorial.\n",
    "        \"\"\"\n",
    "        \n",
    "        label_tutorial = tk.Label(self.tutorial, text=tutorial_text, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        label_tutorial.pack(pady=10)\n",
    "\n",
    "        boton_saltar = tk.Button(self.tutorial, text=\"Saltar Tutorial\", command=self.saltar_tutorial,\n",
    "                                  bg=\"#FFC107\", fg=\"black\", font=(\"Arial\", 12))\n",
    "        boton_saltar.pack(pady=20)\n",
    "\n",
    "    def saltar_tutorial(self):\n",
    "        self.tutorial.destroy()\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            objetos_detectados = set()  # Para almacenar objetos detectados\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                # Prepara la imagen para la detección\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.6:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.classes[class_ids[i]])\n",
    "                        objetos_detectados.add(label)  # Agregar a la lista de objetos detectados\n",
    "                        color = (0, 255, 0)  # Verde por defecto\n",
    "                        if label in [\"knife\", \"pistol\"]:  # Cambiar a rojo si es un objeto peligroso\n",
    "                            color = (255, 0, 0)  # Rojo para objetos peligrosos\n",
    "                            current_time = time.time()\n",
    "                            if self.alarma_activar and (current_time - self.last_alert_time > 3):\n",
    "                                self.reproducir_alerta()\n",
    "                                self.last_alert_time = current_time\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Actualizar el historial de objetos detectados\n",
    "            if objetos_detectados:\n",
    "                self.agregar_historial(f\"Objetos detectados: {', '.join(objetos_detectados)}\")\n",
    "                self.objetos_para_anunciar.update(objetos_detectados)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar and self.voz_activar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            # Detener el hilo de video\n",
    "            if self.thread is not None:\n",
    "                self.thread.join(timeout=1)  # Espera un segundo para que el hilo termine\n",
    "            \n",
    "            # Liberar la cámara\n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            # Actualizar el estado de los botones\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.agregar_historial(\"Foto tomada\")\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.agregar_historial(\"Grabación de video iniciada\")\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.agregar_historial(\"Grabación de video detenida\")\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.boton_voz.config(text=f\"{estado.capitalize()} Voz\")\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.boton_alarma.config(text=f\"{estado.capitalize()} Alarma\")\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        if len(self.historial_detecciones) > 50:  # Limitar el tamaño del historial\n",
    "            self.historial_detecciones.pop(0)\n",
    "        \n",
    "        # Actualizar el historial en el Text\n",
    "        self.text_historial.config(state=tk.NORMAL)  # Habilitar el Text para la edición\n",
    "        self.text_historial.delete(1.0, tk.END)  # Limpiar el Text\n",
    "        self.text_historial.insert(tk.END, \"\\n\".join(self.historial_detecciones))  # Agregar nuevo texto\n",
    "        self.text_historial.config(state=tk.DISABLED)  # Deshabilitar el Text para evitar ediciones\n",
    "        self.text_historial.yview_moveto(1)  # Desplazar hacia abajo\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        archivo = filedialog.asksaveasfile(defaultextension=\".txt\", filetypes=[(\"Text files\", \"*.txt\")])\n",
    "        if archivo:\n",
    "            for entrada in self.historial_detecciones:\n",
    "                archivo.write(entrada + \"\\n\")\n",
    "            archivo.close()\n",
    "            messagebox.showinfo(\"Éxito\", \"Historial descargado correctamente.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()  # Asegurarse de que se cierre la cámara\n",
    "        self.root.quit()  # Cerrar la aplicación\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63b6764-e91c-4cd4-b7d2-3d3d1e4d2f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mejoras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59d6ce76-d77a-4060-828d-646fc6ede4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.logo_imagen_tk = None\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Descargar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.mostrar_tutorial()\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def mostrar_tutorial(self):\n",
    "        self.tutorial = tk.Toplevel(self.root)\n",
    "        self.tutorial.title(\"Tutorial\")\n",
    "        self.tutorial.geometry(\"400x300\")\n",
    "        self.tutorial.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        tutorial_text = \"\"\"\n",
    "        Bienvenido a la aplicación de detección de imágenes.\n",
    "\n",
    "        1. Abrir Cámara: Inicia la cámara para la detección.\n",
    "        2. Detectar Objetos: Activa la detección de objetos en la cámara.\n",
    "        3. Tomar Foto: Captura una imagen de la cámara.\n",
    "        4. Grabar Video: Inicia o detiene la grabación de video.\n",
    "        5. Descargar Historial: Guarda el historial de detecciones en un archivo.\n",
    "        6. Activar Voz: Anuncia los objetos detectados.\n",
    "        7. Activar Alarma: Reproduce una alarma si se detectan objetos peligrosos.\n",
    "        8. Salir: Cierra la aplicación.\n",
    "\n",
    "        Presiona 'Saltar Tutorial' para omitir este tutorial.\n",
    "        \"\"\"\n",
    "        \n",
    "        label_tutorial = tk.Label(self.tutorial, text=tutorial_text, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        label_tutorial.pack(pady=10)\n",
    "\n",
    "        boton_saltar = tk.Button(self.tutorial, text=\"Saltar Tutorial\", command=self.saltar_tutorial,\n",
    "                                  bg=\"#FFC107\", fg=\"black\", font=(\"Arial\", 12))\n",
    "        boton_saltar.pack(pady=20)\n",
    "\n",
    "    def saltar_tutorial(self):\n",
    "        self.tutorial.destroy()\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            objetos_detectados = set()  # Para almacenar objetos detectados\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                # Prepara la imagen para la detección\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.6:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.classes[class_ids[i]])\n",
    "                        objetos_detectados.add(label)  # Agregar a la lista de objetos detectados\n",
    "                        color = (0, 255, 0)  # Verde por defecto\n",
    "                        if label in [\"knife\", \"pistol\"]:  # Cambiar a rojo si es un objeto peligroso\n",
    "                            color = (255, 0, 0)  # Rojo para objetos peligrosos\n",
    "                            current_time = time.time()\n",
    "                            if self.alarma_activar and (current_time - self.last_alert_time > 3):\n",
    "                                self.reproducir_alerta()\n",
    "                                self.last_alert_time = current_time\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Actualizar el historial de objetos detectados\n",
    "            if objetos_detectados:\n",
    "                self.agregar_historial(f\"Objetos detectados: {', '.join(objetos_detectados)}\")\n",
    "                self.objetos_para_anunciar.update(objetos_detectados)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar and self.voz_activar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            # Detener el hilo de video\n",
    "            if self.thread is not None:\n",
    "                self.thread.join(timeout=1)  # Espera un segundo para que el hilo termine\n",
    "            \n",
    "            # Liberar la cámara\n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            # Actualizar el estado de los botones\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.agregar_historial(\"Foto tomada\")\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.agregar_historial(\"Grabación de video iniciada\")\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.agregar_historial(\"Grabación de video detenida\")\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.boton_voz.config(text=f\"{estado.capitalize()} Voz\")\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.boton_alarma.config(text=f\"{estado.capitalize()} Alarma\")\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        if len(self.historial_detecciones) > 50:  # Limitar el tamaño del historial\n",
    "            self.historial_detecciones.pop(0)\n",
    "        \n",
    "        # Actualizar el historial en el Text\n",
    "        self.text_historial.config(state=tk.NORMAL)  # Habilitar el Text para la edición\n",
    "        self.text_historial.delete(1.0, tk.END)  # Limpiar el Text\n",
    "        self.text_historial.insert(tk.END, \"\\n\".join(self.historial_detecciones))  # Agregar nuevo texto\n",
    "        self.text_historial.config(state=tk.DISABLED)  # Deshabilitar el Text para evitar ediciones\n",
    "        self.text_historial.yview_moveto(1)  # Desplazar hacia abajo\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        archivo = filedialog.asksaveasfile(defaultextension=\".txt\", filetypes=[(\"Text files\", \"*.txt\")])\n",
    "        if archivo:\n",
    "            for entrada in self.historial_detecciones:\n",
    "                archivo.write(entrada + \"\\n\")\n",
    "            archivo.close()\n",
    "            messagebox.showinfo(\"Éxito\", \"Historial descargado correctamente.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()  # Asegurarse de que se cierre la cámara\n",
    "        self.root.quit()  # Cerrar la aplicación\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1200x1100\")  # Establecer un tamaño fijo para la ventana\n",
    "root.resizable(False, False)  # Deshabilitar la opción de maximizar\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9afad3f3-cce5-4478-be68-53494f220570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de Imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.clases = []\n",
    "        with open(\"coco-es.names\", \"r\") as f:\n",
    "            self.clases = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.logo_imagen_tk = None\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Descargar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.mostrar_tutorial()\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def mostrar_tutorial(self):\n",
    "        self.tutorial = tk.Toplevel(self.root)\n",
    "        self.tutorial.title(\"Tutorial\")\n",
    "        self.tutorial.geometry(\"400x300\")\n",
    "        self.tutorial.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        tutorial_text = \"\"\"\n",
    "        Bienvenido a la aplicación de detección de imágenes.\n",
    "\n",
    "        1. Abrir Cámara: Inicia la cámara para la detección.\n",
    "        2. Detectar Objetos: Activa la detección de objetos en la cámara.\n",
    "        3. Tomar Foto: Captura una imagen de la cámara.\n",
    "        4. Grabar Video: Inicia o detiene la grabación de video.\n",
    "        5. Descargar Historial: Guarda el historial de detecciones en un archivo.\n",
    "        6. Activar Voz: Anuncia los objetos detectados.\n",
    "        7. Activar Alarma: Reproduce una alarma si se detectan objetos peligrosos.\n",
    "        8. Salir: Cierra la aplicación.\n",
    "\n",
    "        Presiona 'Saltar Tutorial' para omitir este tutorial.\n",
    "        \"\"\"\n",
    "        \n",
    "        label_tutorial = tk.Label(self.tutorial, text=tutorial_text, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        label_tutorial.pack(pady=10)\n",
    "\n",
    "        boton_saltar = tk.Button(self.tutorial, text=\"Saltar Tutorial\", command=self.saltar_tutorial,\n",
    "                                  bg=\"#FFC107\", fg=\"black\", font=(\"Arial\", 12))\n",
    "        boton_saltar.pack(pady=20)\n",
    "\n",
    "    def saltar_tutorial(self):\n",
    "        self.tutorial.destroy()\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            objetos_detectados = set()  # Para almacenar objetos detectados\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                # Prepara la imagen para la detección\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.6:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.clases[class_ids[i]])  # Usar nombres en español\n",
    "                        objetos_detectados.add(label)  # Agregar a la lista de objetos detectados\n",
    "                        color = (0, 255, 0)  # Verde por defecto\n",
    "                        if label in [\"cuchillo\", \"pistola\"]:  # Cambiar a rojo si es un objeto peligroso\n",
    "                            color = (255, 0, 0)  # Rojo para objetos peligrosos\n",
    "                            current_time = time.time()\n",
    "                            if self.alarma_activar and (current_time - self.last_alert_time > 3):\n",
    "                                self.reproducir_alerta()\n",
    "                                self.last_alert_time = current_time\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Actualizar el historial de objetos detectados\n",
    "            if objetos_detectados:\n",
    "                self.agregar_historial(f\"Objetos detectados: {', '.join(objetos_detectados)}\")\n",
    "                self.objetos_para_anunciar.update(objetos_detectados)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar and self.voz_activar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            # Detener el hilo de video\n",
    "            if self.thread is not None:\n",
    "                self.thread.join(timeout=1)  # Espera un segundo para que el hilo termine\n",
    "            \n",
    "            # Liberar la cámara\n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            # Actualizar el estado de los botones\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.agregar_historial(\"Foto tomada\")\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.agregar_historial(\"Grabación de video iniciada\")\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.agregar_historial(\"Grabación de video detenida\")\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.boton_voz.config(text=f\"{estado.capitalize()} Voz\")\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.boton_alarma.config(text=f\"{estado.capitalize()} Alarma\")\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        if len(self.historial_detecciones) > 50:  # Limitar el tamaño del historial\n",
    "            self.historial_detecciones.pop(0)\n",
    "        \n",
    "        # Actualizar el historial en el Text\n",
    "        self.text_historial.config(state=tk.NORMAL)  # Habilitar el Text para la edición\n",
    "        self.text_historial.delete(1.0, tk.END)  # Limpiar el Text\n",
    "        self.text_historial.insert(tk.END, \"\\n\".join(self.historial_detecciones))  # Agregar nuevo texto\n",
    "        self.text_historial.config(state=tk.DISABLED)  # Deshabilitar el Text para evitar ediciones\n",
    "        self.text_historial.yview_moveto(1)  # Desplazar hacia abajo\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        archivo = filedialog.asksaveasfile(defaultextension=\".txt\", filetypes=[(\"Archivos de texto\", \"*.txt\")])\n",
    "        if archivo:\n",
    "            for entrada in self.historial_detecciones:\n",
    "                archivo.write(entrada + \"\\n\")\n",
    "            archivo.close()\n",
    "            messagebox.showinfo(\"Éxito\", \"Historial descargado correctamente.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()  # Asegurarse de que se cierre la cámara\n",
    "        self.root.quit()  # Cerrar la aplicación\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1200x1100\")  # Establecer un tamaño fijo para la ventana\n",
    "root.resizable(False, False)  # Deshabilitar la opción de maximizar\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6706ef70-b65d-40d1-a6dd-2d8c8b2ac6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Intento en español error al intentar usar el archivo en españo, el programa confunde letras y agrega valores numericos envez de leer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35cf79c2-4fe5-4a0d-a3d3-a7535a4abffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de Imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.clases = []\n",
    "        with open(\"coco-es.names\", \"r\") as f:\n",
    "            self.clases = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.logo_imagen_tk = None\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Descargar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.mostrar_tutorial()\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def mostrar_tutorial(self):\n",
    "        self.tutorial = tk.Toplevel(self.root)\n",
    "        self.tutorial.title(\"Tutorial\")\n",
    "        self.tutorial.geometry(\"800x600\")  # Tamaño de la ventana del tutorial\n",
    "        self.tutorial.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        tutorial_text = \"\"\"\n",
    "        Bienvenido a la aplicación de detección de imágenes.\n",
    "\n",
    "        1. Abrir Cámara: Inicia la cámara para la detección.\n",
    "        2. Detectar Objetos: Activa la detección de objetos en la cámara.\n",
    "        3. Tomar Foto: Captura una imagen de la cámara.\n",
    "        4. Grabar Video: Inicia o detiene la grabación de video.\n",
    "        5. Descargar Historial: Guarda el historial de detecciones en un archivo.\n",
    "        6. Activar Voz: Anuncia los objetos detectados.\n",
    "        7. Activar Alarma: Reproduce una alarma si se detectan objetos peligrosos.\n",
    "        8. Salir: Cierra la aplicación.\n",
    "\n",
    "        Presiona 'Saltar Tutorial' para omitir este tutorial.\n",
    "        \"\"\"\n",
    "        \n",
    "        label_tutorial = tk.Label(self.tutorial, text=tutorial_text, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        label_tutorial.pack(pady=10)\n",
    "\n",
    "        boton_saltar = tk.Button(self.tutorial, text=\"Saltar Tutorial\", command=self.saltar_tutorial,\n",
    "                                  bg=\"#FFC107\", fg=\"black\", font=(\"Arial\", 12))\n",
    "        boton_saltar.pack(pady=20)\n",
    "\n",
    "    def saltar_tutorial(self):\n",
    "        self.tutorial.destroy()\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            objetos_detectados = set()  # Para almacenar objetos detectados\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                # Prepara la imagen para la detección\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.6:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.clases[class_ids[i]])  # Usar nombres en español\n",
    "                        objetos_detectados.add(label)  # Agregar a la lista de objetos detectados\n",
    "                        color = (0, 255, 0)  # Verde por defecto\n",
    "                        if label in [\"cuchillo\", \"pistola\"]:  # Cambiar a rojo si es un objeto peligroso\n",
    "                            color = (255, 0, 0)  # Rojo para objetos peligrosos\n",
    "                            current_time = time.time()\n",
    "                            if self.alarma_activar and (current_time - self.last_alert_time > 3):\n",
    "                                self.reproducir_alerta()\n",
    "                                self.last_alert_time = current_time\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Actualizar el historial de objetos detectados\n",
    "            if objetos_detectados:\n",
    "                self.agregar_historial(f\"Objetos detectados: {', '.join(objetos_detectados)}\")\n",
    "                self.objetos_para_anunciar.update(objetos_detectados)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar and self.voz_activar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            # Detener el hilo de video\n",
    "            if self.thread is not None:\n",
    "                self.thread.join(timeout=1)  # Espera un segundo para que el hilo termine\n",
    "            \n",
    "            # Liberar la cámara\n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            # Actualizar el estado de los botones\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.agregar_historial(\"Foto tomada\")\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.agregar_historial(\"Grabación de video iniciada\")\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.agregar_historial(\"Grabación de video detenida\")\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.boton_voz.config(text=f\"{estado.capitalize()} Voz\")\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.boton_alarma.config(text=f\"{estado.capitalize()} Alarma\")\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        if len(self.historial_detecciones) > 50:  # Limitar el tamaño del historial\n",
    "            self.historial_detecciones.pop(0)\n",
    "        \n",
    "        # Actualizar el historial en el Text\n",
    "        self.text_historial.config(state=tk.NORMAL)  # Habilitar el Text para la edición\n",
    "        self.text_historial.delete(1.0, tk.END)  # Limpiar el Text\n",
    "        self.text_historial.insert(tk.END, \"\\n\".join(self.historial_detecciones))  # Agregar nuevo texto\n",
    "        self.text_historial.config(state=tk.DISABLED)  # Deshabilitar el Text para evitar ediciones\n",
    "        self.text_historial.yview_moveto(1)  # Desplazar hacia abajo\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        archivo = filedialog.asksaveasfile(defaultextension=\".txt\", filetypes=[(\"Archivos de texto\", \"*.txt\")])\n",
    "        if archivo:\n",
    "            for entrada in self.historial_detecciones:\n",
    "                archivo.write(entrada + \"\\n\")\n",
    "            archivo.close()\n",
    "            messagebox.showinfo(\"Éxito\", \"Historial descargado correctamente.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()  # Asegurarse de que se cierre la cámara\n",
    "        self.root.quit()  # Cerrar la aplicación\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1200x1100\")  # Establecer un tamaño fijo para la ventana\n",
    "root.resizable(False, False)  # Deshabilitar la opción de maximizar\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8caee168-280d-4ae8-a377-22643214813c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.logo_imagen_tk = None\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Descargar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.mostrar_tutorial()\n",
    "        self.root.after(2000, self.actualizar_historial)  # Programar la actualización del historial cada 2 segundos\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def mostrar_tutorial(self):\n",
    "        self.tutorial = tk.Toplevel(self.root)\n",
    "        self.tutorial.title(\"Tutorial\")\n",
    "        self.tutorial.geometry(\"800x300\")  # Cambiado a 800x300\n",
    "        self.tutorial.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        tutorial_text = \"\"\"\n",
    "        Bienvenido a la aplicación de detección de imágenes.\n",
    "\n",
    "        1. Abrir Cámara: Inicia la cámara para la detección.\n",
    "        2. Detectar Objetos: Activa la detección de objetos en la cámara.\n",
    "        3. Tomar Foto: Captura una imagen de la cámara.\n",
    "        4. Grabar Video: Inicia o detiene la grabación de video.\n",
    "        5. Descargar Historial: Guarda el historial de detecciones en un archivo.\n",
    "        6. Activar Voz: Anuncia los objetos detectados.\n",
    "        7. Activar Alarma: Reproduce una alarma si se detectan objetos peligrosos.\n",
    "        8. Salir: Cierra la aplicación.\n",
    "\n",
    "        Presiona 'Saltar Tutorial' para omitir este tutorial.\n",
    "        \"\"\"\n",
    "        \n",
    "        label_tutorial = tk.Label(self.tutorial, text=tutorial_text, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        label_tutorial.pack(pady=10)\n",
    "\n",
    "        boton_saltar = tk.Button(self.tutorial, text=\"Saltar Tutorial\", command=self.saltar_tutorial,\n",
    "                                  bg=\"#FFC107\", fg=\"black\", font=(\"Arial\", 12))\n",
    "        boton_saltar.pack(pady=20)\n",
    "\n",
    "    def saltar_tutorial(self):\n",
    "        self.tutorial.destroy()\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            objetos_detectados = set()  # Para almacenar objetos detectados\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                # Prepara la imagen para la detección\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.6:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.classes[class_ids[i]])\n",
    "                        objetos_detectados.add(label)  # Agregar a la lista de objetos detectados\n",
    "                        color = (0, 255, 0)  # Verde por defecto\n",
    "                        if label in [\"knife\", \"pistol\"]:  # Cambiar a rojo si es un objeto peligroso\n",
    "                            color = (255, 0, 0)  # Rojo para objetos peligrosos\n",
    "                            current_time = time.time()\n",
    "                            if self.alarma_activar and (current_time - self.last_alert_time > 3):\n",
    "                                self.reproducir_alerta()\n",
    "                                self.last_alert_time = current_time\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Actualizar el historial de objetos detectados\n",
    "            if objetos_detectados:\n",
    "                self.agregar_historial(f\"Objetos detectados: {', '.join(objetos_detectados)}\")\n",
    "                self.objetos_para_anunciar.update(objetos_detectados)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar and self.voz_activar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            # Detener el hilo de video\n",
    "            if self.thread is not None:\n",
    "                self.thread.join(timeout=1)  # Espera un segundo para que el hilo termine\n",
    "            \n",
    "            # Liberar la cámara\n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            # Actualizar el estado de los botones\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.agregar_historial(\"Foto tomada\")\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.agregar_historial(\"Grabación de video iniciada\")\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.agregar_historial(\"Grabación de video detenida\")\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.boton_voz.config(text=f\"{estado.capitalize()} Voz\")\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.boton_alarma.config(text=f\"{estado.capitalize()} Alarma\")\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        if len(self.historial_detecciones) > 50:  # Limitar el tamaño del historial\n",
    "            self.historial_detecciones.pop(0)\n",
    "\n",
    "    def actualizar_historial(self):\n",
    "        # Actualizar el historial en el Text\n",
    "        self.text_historial.config(state=tk.NORMAL)  # Habilitar el Text para la edición\n",
    "        self.text_historial.delete(1.0, tk.END)  # Limpiar el Text\n",
    "        self.text_historial.insert(tk.END, \"\\n\".join(self.historial_detecciones))  # Agregar nuevo texto\n",
    "        self.text_historial.config(state=tk.DISABLED)  # Deshabilitar el Text para evitar ediciones\n",
    "        self.text_historial.yview_moveto(1)\n",
    "\n",
    "        self.root.after(2000, self.actualizar_historial)  \n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        archivo = filedialog.asksaveasfile(defaultextension=\".txt\", filetypes=[(\"Text files\", \"*.txt\")])\n",
    "        if archivo:\n",
    "            for entrada in self.historial_detecciones:\n",
    "                archivo.write(entrada + \"\\n\")\n",
    "            archivo.close()\n",
    "            messagebox.showinfo(\"Éxito\", \"Historial descargado correctamente.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()  # Asegurarse de que se cierre la cámara\n",
    "        self.root.quit()  # Cerrar la aplicación\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1200x1100\")  # Establecer un tamaño fijo para la ventana\n",
    "root.resizable(False, False)  # Deshabilitar la opción de maximizar\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98881b2f-339c-439a-a35c-38a25e0934c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Intento con yolo8 , se detectan mas cosas ¿menor precision o mayor?,se va a seguir probndo para comprobarlo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87583488-f7f6-47da-a168-8fa6612f4da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 person, 199.5ms\n",
      "Speed: 13.1ms preprocess, 199.5ms inference, 17.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.1ms\n",
      "Speed: 4.0ms preprocess, 74.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 105.3ms\n",
      "Speed: 3.5ms preprocess, 105.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 74.9ms\n",
      "Speed: 3.0ms preprocess, 74.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 75.2ms\n",
      "Speed: 3.0ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 91.2ms\n",
      "Speed: 3.5ms preprocess, 91.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 79.2ms\n",
      "Speed: 2.0ms preprocess, 79.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 77.2ms\n",
      "Speed: 2.5ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 81.1ms\n",
      "Speed: 2.5ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 97.5ms\n",
      "Speed: 6.6ms preprocess, 97.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 76.1ms\n",
      "Speed: 4.0ms preprocess, 76.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 84.1ms\n",
      "Speed: 2.0ms preprocess, 84.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 83.3ms\n",
      "Speed: 2.5ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 110.2ms\n",
      "Speed: 3.0ms preprocess, 110.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 78.2ms\n",
      "Speed: 2.0ms preprocess, 78.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 77.9ms\n",
      "Speed: 3.0ms preprocess, 77.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 75.7ms\n",
      "Speed: 2.5ms preprocess, 75.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 86.6ms\n",
      "Speed: 4.5ms preprocess, 86.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 72.6ms\n",
      "Speed: 3.5ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 71.7ms\n",
      "Speed: 2.2ms preprocess, 71.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 77.0ms\n",
      "Speed: 2.5ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 80.6ms\n",
      "Speed: 2.4ms preprocess, 80.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.8ms\n",
      "Speed: 4.0ms preprocess, 69.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 77.5ms\n",
      "Speed: 1.0ms preprocess, 77.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 77.1ms\n",
      "Speed: 2.0ms preprocess, 77.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 79.0ms\n",
      "Speed: 1.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 72.9ms\n",
      "Speed: 2.0ms preprocess, 72.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 76.4ms\n",
      "Speed: 3.2ms preprocess, 76.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 83.9ms\n",
      "Speed: 4.6ms preprocess, 83.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 75.2ms\n",
      "Speed: 2.2ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.5ms\n",
      "Speed: 2.5ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.2ms\n",
      "Speed: 4.5ms preprocess, 73.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 74.7ms\n",
      "Speed: 3.5ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 73.3ms\n",
      "Speed: 2.2ms preprocess, 73.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 73.4ms\n",
      "Speed: 2.5ms preprocess, 73.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 74.4ms\n",
      "Speed: 1.0ms preprocess, 74.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 77.2ms\n",
      "Speed: 2.0ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 93.8ms\n",
      "Speed: 2.9ms preprocess, 93.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 76.7ms\n",
      "Speed: 2.5ms preprocess, 76.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 74.7ms\n",
      "Speed: 4.0ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 79.7ms\n",
      "Speed: 2.0ms preprocess, 79.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 80.8ms\n",
      "Speed: 3.0ms preprocess, 80.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 75.9ms\n",
      "Speed: 2.0ms preprocess, 75.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 73.4ms\n",
      "Speed: 2.0ms preprocess, 73.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 71.4ms\n",
      "Speed: 2.0ms preprocess, 71.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 74.4ms\n",
      "Speed: 1.5ms preprocess, 74.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 cell phones, 86.0ms\n",
      "Speed: 3.0ms preprocess, 86.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 72.6ms\n",
      "Speed: 3.5ms preprocess, 72.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 72.5ms\n",
      "Speed: 3.0ms preprocess, 72.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 76.3ms\n",
      "Speed: 3.5ms preprocess, 76.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 74.8ms\n",
      "Speed: 1.5ms preprocess, 74.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 79.0ms\n",
      "Speed: 2.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 cell phones, 70.9ms\n",
      "Speed: 1.5ms preprocess, 70.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 91.1ms\n",
      "Speed: 3.5ms preprocess, 91.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cake, 78.4ms\n",
      "Speed: 4.0ms preprocess, 78.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.6ms\n",
      "Speed: 2.3ms preprocess, 84.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 75.0ms\n",
      "Speed: 2.5ms preprocess, 75.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 77.3ms\n",
      "Speed: 1.0ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 72.6ms\n",
      "Speed: 2.5ms preprocess, 72.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 75.6ms\n",
      "Speed: 3.0ms preprocess, 75.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 72.5ms\n",
      "Speed: 2.6ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 81.1ms\n",
      "Speed: 3.1ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 1 cake, 82.2ms\n",
      "Speed: 3.2ms preprocess, 82.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 apples, 68.8ms\n",
      "Speed: 2.0ms preprocess, 68.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 86.6ms\n",
      "Speed: 4.0ms preprocess, 86.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 apples, 77.3ms\n",
      "Speed: 2.2ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 73.7ms\n",
      "Speed: 3.0ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 68.7ms\n",
      "Speed: 4.0ms preprocess, 68.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 apples, 79.5ms\n",
      "Speed: 3.5ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 apples, 73.0ms\n",
      "Speed: 3.0ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 apples, 72.9ms\n",
      "Speed: 2.7ms preprocess, 72.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 73.7ms\n",
      "Speed: 2.5ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 81.5ms\n",
      "Speed: 2.0ms preprocess, 81.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 81.0ms\n",
      "Speed: 2.5ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 apples, 73.1ms\n",
      "Speed: 3.0ms preprocess, 73.1ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 1 pizza, 77.6ms\n",
      "Speed: 2.5ms preprocess, 77.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 apples, 77.2ms\n",
      "Speed: 2.1ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 apples, 1 book, 82.3ms\n",
      "Speed: 2.5ms preprocess, 82.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 apples, 76.2ms\n",
      "Speed: 1.5ms preprocess, 76.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 78.2ms\n",
      "Speed: 2.5ms preprocess, 78.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 apples, 75.7ms\n",
      "Speed: 3.0ms preprocess, 75.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 apples, 1 cake, 79.8ms\n",
      "Speed: 2.0ms preprocess, 79.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 apples, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 apples, 72.5ms\n",
      "Speed: 3.5ms preprocess, 72.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 4 apples, 73.8ms\n",
      "Speed: 1.5ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 88.7ms\n",
      "Speed: 2.5ms preprocess, 88.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 76.1ms\n",
      "Speed: 2.0ms preprocess, 76.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 79.1ms\n",
      "Speed: 2.0ms preprocess, 79.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.2ms\n",
      "Speed: 3.0ms preprocess, 79.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.6ms\n",
      "Speed: 2.8ms preprocess, 79.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.8ms\n",
      "Speed: 3.0ms preprocess, 78.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.5ms\n",
      "Speed: 2.5ms preprocess, 73.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.0ms\n",
      "Speed: 3.1ms preprocess, 76.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 70.3ms\n",
      "Speed: 3.0ms preprocess, 70.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.1ms\n",
      "Speed: 1.0ms preprocess, 76.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 78.6ms\n",
      "Speed: 2.0ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.7ms\n",
      "Speed: 2.2ms preprocess, 75.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.2ms\n",
      "Speed: 3.0ms preprocess, 76.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.9ms\n",
      "Speed: 2.5ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.5ms\n",
      "Speed: 4.6ms preprocess, 83.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 81.5ms\n",
      "Speed: 3.0ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 95.4ms\n",
      "Speed: 2.0ms preprocess, 95.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 79.0ms\n",
      "Speed: 2.0ms preprocess, 79.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 80.5ms\n",
      "Speed: 4.5ms preprocess, 80.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 78.6ms\n",
      "Speed: 3.0ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.0ms\n",
      "Speed: 2.0ms preprocess, 74.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 100.6ms\n",
      "Speed: 2.0ms preprocess, 100.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.6ms\n",
      "Speed: 1.0ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 76.2ms\n",
      "Speed: 1.0ms preprocess, 76.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 apple, 76.2ms\n",
      "Speed: 3.5ms preprocess, 76.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 donut, 75.4ms\n",
      "Speed: 3.4ms preprocess, 75.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 79.3ms\n",
      "Speed: 2.0ms preprocess, 79.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 77.9ms\n",
      "Speed: 2.0ms preprocess, 77.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.4ms\n",
      "Speed: 3.0ms preprocess, 73.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.3ms\n",
      "Speed: 4.0ms preprocess, 73.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.2ms\n",
      "Speed: 4.0ms preprocess, 79.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cats, 75.4ms\n",
      "Speed: 1.5ms preprocess, 75.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 73.8ms\n",
      "Speed: 3.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 73.4ms\n",
      "Speed: 2.5ms preprocess, 73.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 76.8ms\n",
      "Speed: 3.0ms preprocess, 76.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 79.7ms\n",
      "Speed: 2.5ms preprocess, 79.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 73.8ms\n",
      "Speed: 3.5ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.3ms\n",
      "Speed: 2.9ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cake, 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 68.6ms\n",
      "Speed: 3.5ms preprocess, 68.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 82.5ms\n",
      "Speed: 2.6ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 101.0ms\n",
      "Speed: 3.0ms preprocess, 101.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.1ms\n",
      "Speed: 4.0ms preprocess, 74.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 vase, 80.4ms\n",
      "Speed: 2.1ms preprocess, 80.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 77.9ms\n",
      "Speed: 3.0ms preprocess, 77.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 77.8ms\n",
      "Speed: 2.0ms preprocess, 77.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.1ms\n",
      "Speed: 2.0ms preprocess, 79.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 77.2ms\n",
      "Speed: 1.0ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 78.3ms\n",
      "Speed: 2.0ms preprocess, 78.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 74.7ms\n",
      "Speed: 2.5ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 76.8ms\n",
      "Speed: 2.5ms preprocess, 76.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 79.7ms\n",
      "Speed: 2.9ms preprocess, 79.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 99.5ms\n",
      "Speed: 3.5ms preprocess, 99.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 pizza, 90.2ms\n",
      "Speed: 2.5ms preprocess, 90.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 pizza, 74.8ms\n",
      "Speed: 2.1ms preprocess, 74.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 pizza, 83.2ms\n",
      "Speed: 4.0ms preprocess, 83.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 donuts, 74.7ms\n",
      "Speed: 3.0ms preprocess, 74.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cake, 76.5ms\n",
      "Speed: 2.5ms preprocess, 76.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 74.6ms\n",
      "Speed: 2.0ms preprocess, 74.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 76.4ms\n",
      "Speed: 1.5ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 83.9ms\n",
      "Speed: 2.5ms preprocess, 83.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.4ms\n",
      "Speed: 3.5ms preprocess, 82.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.8ms\n",
      "Speed: 2.0ms preprocess, 78.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 78.7ms\n",
      "Speed: 3.0ms preprocess, 78.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 86.1ms\n",
      "Speed: 2.0ms preprocess, 86.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 78.6ms\n",
      "Speed: 2.0ms preprocess, 78.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 78.3ms\n",
      "Speed: 3.0ms preprocess, 78.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 76.5ms\n",
      "Speed: 2.0ms preprocess, 76.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 83.1ms\n",
      "Speed: 2.0ms preprocess, 83.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 78.8ms\n",
      "Speed: 2.5ms preprocess, 78.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 83.2ms\n",
      "Speed: 2.5ms preprocess, 83.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.5ms\n",
      "Speed: 2.5ms preprocess, 74.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 76.5ms\n",
      "Speed: 3.5ms preprocess, 76.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 78.2ms\n",
      "Speed: 3.0ms preprocess, 78.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 donuts, 75.8ms\n",
      "Speed: 2.8ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 83.1ms\n",
      "Speed: 2.0ms preprocess, 83.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 76.1ms\n",
      "Speed: 3.1ms preprocess, 76.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 donuts, 82.0ms\n",
      "Speed: 3.4ms preprocess, 82.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 78.9ms\n",
      "Speed: 4.0ms preprocess, 78.9ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 1 cake, 73.2ms\n",
      "Speed: 2.0ms preprocess, 73.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 76.2ms\n",
      "Speed: 2.0ms preprocess, 76.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.6ms\n",
      "Speed: 3.0ms preprocess, 76.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.6ms\n",
      "Speed: 1.0ms preprocess, 80.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 105.1ms\n",
      "Speed: 2.0ms preprocess, 105.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 80.4ms\n",
      "Speed: 3.0ms preprocess, 80.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.9ms\n",
      "Speed: 3.0ms preprocess, 77.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 71.9ms\n",
      "Speed: 2.5ms preprocess, 71.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 89.4ms\n",
      "Speed: 2.5ms preprocess, 89.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 75.1ms\n",
      "Speed: 2.0ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.8ms\n",
      "Speed: 2.0ms preprocess, 78.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 83.1ms\n",
      "Speed: 2.5ms preprocess, 83.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 69.5ms\n",
      "Speed: 2.0ms preprocess, 69.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 77.7ms\n",
      "Speed: 2.0ms preprocess, 77.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 76.2ms\n",
      "Speed: 2.5ms preprocess, 76.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.3ms\n",
      "Speed: 3.0ms preprocess, 80.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 73.9ms\n",
      "Speed: 2.5ms preprocess, 73.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 80.0ms\n",
      "Speed: 3.0ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 89.2ms\n",
      "Speed: 2.0ms preprocess, 89.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 75.1ms\n",
      "Speed: 2.5ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.9ms\n",
      "Speed: 4.0ms preprocess, 74.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.2ms\n",
      "Speed: 2.5ms preprocess, 77.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.0ms\n",
      "Speed: 3.9ms preprocess, 77.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.2ms\n",
      "Speed: 3.0ms preprocess, 77.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 73.7ms\n",
      "Speed: 2.0ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 81.7ms\n",
      "Speed: 2.0ms preprocess, 81.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 car, 73.2ms\n",
      "Speed: 2.5ms preprocess, 73.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 81.3ms\n",
      "Speed: 3.4ms preprocess, 81.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.0ms\n",
      "Speed: 2.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.4ms\n",
      "Speed: 3.5ms preprocess, 79.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 85.1ms\n",
      "Speed: 2.5ms preprocess, 85.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 73.8ms\n",
      "Speed: 2.5ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.7ms\n",
      "Speed: 2.5ms preprocess, 77.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 74.5ms\n",
      "Speed: 2.0ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 cell phone, 75.5ms\n",
      "Speed: 2.0ms preprocess, 75.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 laptop, 112.7ms\n",
      "Speed: 3.0ms preprocess, 112.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 84.2ms\n",
      "Speed: 2.5ms preprocess, 84.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 carrot, 75.9ms\n",
      "Speed: 2.0ms preprocess, 75.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 fire hydrant, 74.1ms\n",
      "Speed: 2.0ms preprocess, 74.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.0ms\n",
      "Speed: 2.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 78.8ms\n",
      "Speed: 2.0ms preprocess, 78.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 72.1ms\n",
      "Speed: 2.3ms preprocess, 72.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.7ms\n",
      "Speed: 1.5ms preprocess, 85.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 hot dog, 70.6ms\n",
      "Speed: 3.0ms preprocess, 70.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 carrot, 1 cell phone, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 78.2ms\n",
      "Speed: 3.0ms preprocess, 78.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.7ms\n",
      "Speed: 1.5ms preprocess, 78.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 72.0ms\n",
      "Speed: 4.1ms preprocess, 72.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.4ms\n",
      "Speed: 2.0ms preprocess, 79.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.8ms\n",
      "Speed: 2.5ms preprocess, 81.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 81.2ms\n",
      "Speed: 2.5ms preprocess, 81.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 fire hydrant, 1 donut, 75.2ms\n",
      "Speed: 2.0ms preprocess, 75.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 hot dog, 1 donut, 77.6ms\n",
      "Speed: 3.0ms preprocess, 77.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 donut, 74.4ms\n",
      "Speed: 2.0ms preprocess, 74.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 carrot, 1 donut, 79.2ms\n",
      "Speed: 2.0ms preprocess, 79.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 carrots, 1 donut, 73.0ms\n",
      "Speed: 3.0ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 carrot, 1 donut, 72.9ms\n",
      "Speed: 4.0ms preprocess, 72.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 carrots, 77.9ms\n",
      "Speed: 1.0ms preprocess, 77.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 carrots, 84.1ms\n",
      "Speed: 1.0ms preprocess, 84.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 carrot, 1 hot dog, 1 donut, 81.1ms\n",
      "Speed: 2.5ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 carrot, 82.7ms\n",
      "Speed: 2.0ms preprocess, 82.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 carrot, 1 donut, 72.3ms\n",
      "Speed: 2.0ms preprocess, 72.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 carrot, 1 donut, 76.3ms\n",
      "Speed: 2.5ms preprocess, 76.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 carrot, 79.8ms\n",
      "Speed: 2.3ms preprocess, 79.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 73.7ms\n",
      "Speed: 1.5ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 carrot, 79.9ms\n",
      "Speed: 2.5ms preprocess, 79.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 107.2ms\n",
      "Speed: 1.0ms preprocess, 107.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 carrot, 80.6ms\n",
      "Speed: 2.0ms preprocess, 80.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.8ms\n",
      "Speed: 2.2ms preprocess, 79.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 carrot, 1 donut, 82.4ms\n",
      "Speed: 1.0ms preprocess, 82.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.4ms\n",
      "Speed: 2.0ms preprocess, 79.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.9ms\n",
      "Speed: 2.0ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 book, 83.6ms\n",
      "Speed: 3.0ms preprocess, 83.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 toothbrush, 77.1ms\n",
      "Speed: 3.0ms preprocess, 77.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 teddy bear, 76.1ms\n",
      "Speed: 4.5ms preprocess, 76.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 teddy bear, 88.8ms\n",
      "Speed: 2.0ms preprocess, 88.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 teddy bear, 74.8ms\n",
      "Speed: 3.0ms preprocess, 74.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.8ms\n",
      "Speed: 3.5ms preprocess, 81.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cat, 77.8ms\n",
      "Speed: 3.0ms preprocess, 77.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bicycle, 78.5ms\n",
      "Speed: 4.1ms preprocess, 78.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bicycle, 76.3ms\n",
      "Speed: 2.5ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.3ms\n",
      "Speed: 3.0ms preprocess, 85.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 bottle, 84.3ms\n",
      "Speed: 4.0ms preprocess, 84.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.4ms\n",
      "Speed: 3.0ms preprocess, 74.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.0ms\n",
      "Speed: 2.0ms preprocess, 79.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 76.8ms\n",
      "Speed: 2.0ms preprocess, 76.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.1ms\n",
      "Speed: 2.0ms preprocess, 78.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 73.3ms\n",
      "Speed: 3.5ms preprocess, 73.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 83.8ms\n",
      "Speed: 3.0ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 85.1ms\n",
      "Speed: 3.0ms preprocess, 85.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.6ms\n",
      "Speed: 2.0ms preprocess, 84.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.2ms\n",
      "Speed: 3.5ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cat, 72.8ms\n",
      "Speed: 2.4ms preprocess, 72.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.9ms\n",
      "Speed: 1.0ms preprocess, 75.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.8ms\n",
      "Speed: 2.0ms preprocess, 75.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.3ms\n",
      "Speed: 2.5ms preprocess, 84.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 75.4ms\n",
      "Speed: 3.0ms preprocess, 75.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 98.1ms\n",
      "Speed: 2.5ms preprocess, 98.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 85.6ms\n",
      "Speed: 2.0ms preprocess, 85.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 72.8ms\n",
      "Speed: 2.0ms preprocess, 72.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 74.2ms\n",
      "Speed: 3.1ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 donut, 74.7ms\n",
      "Speed: 3.0ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 apple, 1 donut, 1 cake, 76.3ms\n",
      "Speed: 2.0ms preprocess, 76.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 apple, 1 donut, 75.7ms\n",
      "Speed: 4.0ms preprocess, 75.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 apple, 1 donut, 76.5ms\n",
      "Speed: 3.5ms preprocess, 76.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 1 donut, 78.8ms\n",
      "Speed: 3.5ms preprocess, 78.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cake, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 87.1ms\n",
      "Speed: 1.5ms preprocess, 87.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.0ms\n",
      "Speed: 2.5ms preprocess, 77.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 80.7ms\n",
      "Speed: 3.1ms preprocess, 80.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 82.9ms\n",
      "Speed: 2.0ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 72.3ms\n",
      "Speed: 3.2ms preprocess, 72.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 77.5ms\n",
      "Speed: 2.0ms preprocess, 77.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 cell phone, 78.3ms\n",
      "Speed: 3.5ms preprocess, 78.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 traffic light, 2 apples, 1 cell phone, 84.2ms\n",
      "Speed: 3.0ms preprocess, 84.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 76.9ms\n",
      "Speed: 2.0ms preprocess, 76.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 apple, 1 cell phone, 79.8ms\n",
      "Speed: 3.3ms preprocess, 79.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 apples, 1 cell phone, 78.6ms\n",
      "Speed: 3.5ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 1 traffic light, 1 apple, 78.8ms\n",
      "Speed: 4.0ms preprocess, 78.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.6ms\n",
      "Speed: 2.5ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 73.2ms\n",
      "Speed: 2.0ms preprocess, 73.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 78.5ms\n",
      "Speed: 2.0ms preprocess, 78.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 79.7ms\n",
      "Speed: 2.0ms preprocess, 79.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 79.2ms\n",
      "Speed: 2.0ms preprocess, 79.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 66.9ms\n",
      "Speed: 2.0ms preprocess, 66.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 69.6ms\n",
      "Speed: 3.1ms preprocess, 69.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 72.8ms\n",
      "Speed: 2.6ms preprocess, 72.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 72.5ms\n",
      "Speed: 4.0ms preprocess, 72.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 72.7ms\n",
      "Speed: 3.0ms preprocess, 72.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.7ms\n",
      "Speed: 4.0ms preprocess, 74.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 100.1ms\n",
      "Speed: 5.0ms preprocess, 100.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 85.5ms\n",
      "Speed: 1.0ms preprocess, 85.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 umbrella, 71.8ms\n",
      "Speed: 3.0ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 80.1ms\n",
      "Speed: 2.0ms preprocess, 80.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.1ms\n",
      "Speed: 3.0ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.3ms\n",
      "Speed: 1.5ms preprocess, 78.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 89.8ms\n",
      "Speed: 4.0ms preprocess, 89.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 84.1ms\n",
      "Speed: 2.0ms preprocess, 84.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cake, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cake, 74.2ms\n",
      "Speed: 2.0ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.3ms\n",
      "Speed: 1.5ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 85.1ms\n",
      "Speed: 3.1ms preprocess, 85.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 car, 85.6ms\n",
      "Speed: 1.6ms preprocess, 85.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 80.4ms\n",
      "Speed: 2.1ms preprocess, 80.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 parking meter, 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 81.6ms\n",
      "Speed: 2.0ms preprocess, 81.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 72.0ms\n",
      "Speed: 2.5ms preprocess, 72.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.3ms\n",
      "Speed: 1.8ms preprocess, 78.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 73.8ms\n",
      "Speed: 1.5ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.0ms\n",
      "Speed: 3.0ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.5ms\n",
      "Speed: 2.5ms preprocess, 77.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.3ms\n",
      "Speed: 2.6ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.8ms\n",
      "Speed: 2.9ms preprocess, 83.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 85.0ms\n",
      "Speed: 2.0ms preprocess, 85.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.7ms\n",
      "Speed: 4.6ms preprocess, 79.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.1ms\n",
      "Speed: 2.0ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 76.3ms\n",
      "Speed: 1.5ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.2ms\n",
      "Speed: 2.0ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cell phone, 82.5ms\n",
      "Speed: 2.0ms preprocess, 82.5ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 79.9ms\n",
      "Speed: 3.0ms preprocess, 79.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.4ms\n",
      "Speed: 2.3ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.1ms\n",
      "Speed: 1.5ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.3ms\n",
      "Speed: 1.0ms preprocess, 89.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 99.6ms\n",
      "Speed: 2.0ms preprocess, 99.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 88.3ms\n",
      "Speed: 1.6ms preprocess, 88.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.5ms\n",
      "Speed: 3.0ms preprocess, 78.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.2ms\n",
      "Speed: 2.0ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.9ms\n",
      "Speed: 3.0ms preprocess, 76.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.4ms\n",
      "Speed: 2.6ms preprocess, 73.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 85.4ms\n",
      "Speed: 3.1ms preprocess, 85.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.7ms\n",
      "Speed: 3.0ms preprocess, 77.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 toothbrush, 72.5ms\n",
      "Speed: 2.0ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.4ms\n",
      "Speed: 2.5ms preprocess, 77.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.3ms\n",
      "Speed: 2.0ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.6ms\n",
      "Speed: 3.0ms preprocess, 74.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 90.7ms\n",
      "Speed: 2.5ms preprocess, 90.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 88.3ms\n",
      "Speed: 2.0ms preprocess, 88.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 72.0ms\n",
      "Speed: 1.9ms preprocess, 72.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.7ms\n",
      "Speed: 1.5ms preprocess, 73.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 traffic light, 74.1ms\n",
      "Speed: 3.0ms preprocess, 74.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 71.8ms\n",
      "Speed: 2.7ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.3ms\n",
      "Speed: 3.5ms preprocess, 78.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.9ms\n",
      "Speed: 4.0ms preprocess, 75.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 86.6ms\n",
      "Speed: 1.0ms preprocess, 86.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.5ms\n",
      "Speed: 3.8ms preprocess, 80.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 73.4ms\n",
      "Speed: 2.0ms preprocess, 73.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.1ms\n",
      "Speed: 2.0ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 1 oven, 72.9ms\n",
      "Speed: 1.0ms preprocess, 72.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 71.4ms\n",
      "Speed: 2.0ms preprocess, 71.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 pizza, 75.3ms\n",
      "Speed: 2.0ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 pizza, 78.9ms\n",
      "Speed: 3.2ms preprocess, 78.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 1 oven, 74.3ms\n",
      "Speed: 2.5ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 1 oven, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 pizza, 1 oven, 79.0ms\n",
      "Speed: 2.5ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 1 oven, 90.7ms\n",
      "Speed: 3.5ms preprocess, 90.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 oven, 74.6ms\n",
      "Speed: 2.0ms preprocess, 74.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.3ms\n",
      "Speed: 3.1ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.3ms\n",
      "Speed: 3.0ms preprocess, 85.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.4ms\n",
      "Speed: 2.5ms preprocess, 82.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.0ms\n",
      "Speed: 3.5ms preprocess, 82.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.2ms\n",
      "Speed: 2.0ms preprocess, 81.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 86.7ms\n",
      "Speed: 2.0ms preprocess, 86.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 86.0ms\n",
      "Speed: 3.9ms preprocess, 86.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 87.5ms\n",
      "Speed: 2.0ms preprocess, 87.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.5ms\n",
      "Speed: 2.5ms preprocess, 75.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.9ms\n",
      "Speed: 3.0ms preprocess, 79.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.0ms\n",
      "Speed: 3.5ms preprocess, 75.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.2ms\n",
      "Speed: 4.5ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.2ms\n",
      "Speed: 1.4ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.4ms\n",
      "Speed: 3.5ms preprocess, 76.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.6ms\n",
      "Speed: 3.0ms preprocess, 83.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 75.5ms\n",
      "Speed: 2.0ms preprocess, 75.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.7ms\n",
      "Speed: 3.0ms preprocess, 84.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 2.5ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 teddy bear, 78.6ms\n",
      "Speed: 4.3ms preprocess, 78.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 surfboard, 87.7ms\n",
      "Speed: 1.5ms preprocess, 87.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 donut, 79.2ms\n",
      "Speed: 2.0ms preprocess, 79.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.6ms\n",
      "Speed: 2.1ms preprocess, 82.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.1ms\n",
      "Speed: 1.5ms preprocess, 77.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.9ms\n",
      "Speed: 3.0ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 86.6ms\n",
      "Speed: 3.4ms preprocess, 86.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.5ms\n",
      "Speed: 3.0ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.5ms\n",
      "Speed: 3.0ms preprocess, 78.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 99.8ms\n",
      "Speed: 3.9ms preprocess, 99.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.4ms\n",
      "Speed: 3.1ms preprocess, 81.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.5ms\n",
      "Speed: 2.6ms preprocess, 75.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.8ms\n",
      "Speed: 3.5ms preprocess, 80.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.8ms\n",
      "Speed: 3.0ms preprocess, 80.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.5ms\n",
      "Speed: 2.0ms preprocess, 82.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.5ms\n",
      "Speed: 3.0ms preprocess, 83.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 100.6ms\n",
      "Speed: 3.0ms preprocess, 100.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.5ms\n",
      "Speed: 3.0ms preprocess, 82.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.8ms\n",
      "Speed: 2.5ms preprocess, 74.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 88.4ms\n",
      "Speed: 3.3ms preprocess, 88.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 72.9ms\n",
      "Speed: 1.7ms preprocess, 72.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.4ms\n",
      "Speed: 2.5ms preprocess, 77.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 72.5ms\n",
      "Speed: 3.5ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.4ms\n",
      "Speed: 1.2ms preprocess, 74.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.7ms\n",
      "Speed: 2.5ms preprocess, 81.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cat, 83.1ms\n",
      "Speed: 2.0ms preprocess, 83.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 76.6ms\n",
      "Speed: 2.2ms preprocess, 76.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 75.6ms\n",
      "Speed: 4.3ms preprocess, 75.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.0ms\n",
      "Speed: 4.2ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cat, 77.4ms\n",
      "Speed: 2.5ms preprocess, 77.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 teddy bear, 78.4ms\n",
      "Speed: 2.0ms preprocess, 78.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 teddy bear, 87.6ms\n",
      "Speed: 2.7ms preprocess, 87.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.8ms\n",
      "Speed: 4.0ms preprocess, 85.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.4ms\n",
      "Speed: 2.0ms preprocess, 80.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.2ms\n",
      "Speed: 2.0ms preprocess, 80.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.8ms\n",
      "Speed: 2.0ms preprocess, 78.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.9ms\n",
      "Speed: 2.5ms preprocess, 80.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.3ms\n",
      "Speed: 2.0ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.7ms\n",
      "Speed: 3.0ms preprocess, 83.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.1ms\n",
      "Speed: 2.5ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 77.6ms\n",
      "Speed: 2.0ms preprocess, 77.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.6ms\n",
      "Speed: 3.5ms preprocess, 93.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.5ms\n",
      "Speed: 3.0ms preprocess, 76.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.0ms\n",
      "Speed: 3.0ms preprocess, 77.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.8ms\n",
      "Speed: 2.0ms preprocess, 78.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.2ms\n",
      "Speed: 2.0ms preprocess, 80.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 teddy bear, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 1 teddy bear, 80.5ms\n",
      "Speed: 2.0ms preprocess, 80.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.9ms\n",
      "Speed: 2.0ms preprocess, 85.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 teddy bear, 80.1ms\n",
      "Speed: 2.2ms preprocess, 80.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 teddy bear, 73.3ms\n",
      "Speed: 3.5ms preprocess, 73.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 75.0ms\n",
      "Speed: 3.5ms preprocess, 75.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.0ms\n",
      "Speed: 2.0ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.6ms\n",
      "Speed: 3.5ms preprocess, 79.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 81.1ms\n",
      "Speed: 3.5ms preprocess, 81.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.2ms\n",
      "Speed: 2.5ms preprocess, 84.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.8ms\n",
      "Speed: 3.5ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 76.1ms\n",
      "Speed: 1.0ms preprocess, 76.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 stop sign, 87.1ms\n",
      "Speed: 2.0ms preprocess, 87.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.7ms\n",
      "Speed: 3.6ms preprocess, 80.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.6ms\n",
      "Speed: 3.3ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.9ms\n",
      "Speed: 2.5ms preprocess, 82.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.2ms\n",
      "Speed: 2.0ms preprocess, 78.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 83.6ms\n",
      "Speed: 2.5ms preprocess, 83.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.8ms\n",
      "Speed: 4.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.7ms\n",
      "Speed: 4.5ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 donut, 83.3ms\n",
      "Speed: 2.0ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 80.3ms\n",
      "Speed: 2.3ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.9ms\n",
      "Speed: 4.0ms preprocess, 77.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.6ms\n",
      "Speed: 2.0ms preprocess, 79.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 79.8ms\n",
      "Speed: 2.0ms preprocess, 79.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 1 laptop, 74.0ms\n",
      "Speed: 2.0ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 vase, 79.8ms\n",
      "Speed: 2.0ms preprocess, 79.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 74.9ms\n",
      "Speed: 3.0ms preprocess, 74.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 80.1ms\n",
      "Speed: 1.5ms preprocess, 80.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 80.6ms\n",
      "Speed: 2.5ms preprocess, 80.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 73.7ms\n",
      "Speed: 1.5ms preprocess, 73.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 70.5ms\n",
      "Speed: 2.0ms preprocess, 70.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 77.8ms\n",
      "Speed: 2.0ms preprocess, 77.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 apple, 97.6ms\n",
      "Speed: 2.0ms preprocess, 97.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 apples, 73.8ms\n",
      "Speed: 3.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.5ms\n",
      "Speed: 2.5ms preprocess, 74.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 74.5ms\n",
      "Speed: 2.0ms preprocess, 74.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 apple, 78.6ms\n",
      "Speed: 2.6ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.4ms\n",
      "Speed: 3.0ms preprocess, 77.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 68.3ms\n",
      "Speed: 2.7ms preprocess, 68.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 1 teddy bear, 79.6ms\n",
      "Speed: 1.5ms preprocess, 79.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 81.1ms\n",
      "Speed: 2.0ms preprocess, 81.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 79.6ms\n",
      "Speed: 2.0ms preprocess, 79.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 71.5ms\n",
      "Speed: 3.0ms preprocess, 71.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 81.2ms\n",
      "Speed: 2.5ms preprocess, 81.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 75.5ms\n",
      "Speed: 2.5ms preprocess, 75.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 74.3ms\n",
      "Speed: 1.0ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 1 teddy bear, 80.4ms\n",
      "Speed: 2.0ms preprocess, 80.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 77.0ms\n",
      "Speed: 4.5ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 77.5ms\n",
      "Speed: 2.0ms preprocess, 77.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 76.3ms\n",
      "Speed: 3.0ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 67.3ms\n",
      "Speed: 2.0ms preprocess, 67.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 73.5ms\n",
      "Speed: 2.0ms preprocess, 73.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 73.7ms\n",
      "Speed: 1.0ms preprocess, 73.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 75.8ms\n",
      "Speed: 2.0ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.8ms\n",
      "Speed: 2.0ms preprocess, 73.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 75.0ms\n",
      "Speed: 2.0ms preprocess, 75.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.2ms\n",
      "Speed: 2.0ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 79.7ms\n",
      "Speed: 2.0ms preprocess, 79.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 teddy bear, 70.8ms\n",
      "Speed: 1.0ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.9ms\n",
      "Speed: 3.5ms preprocess, 74.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.1ms\n",
      "Speed: 3.0ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.9ms\n",
      "Speed: 2.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 88.4ms\n",
      "Speed: 3.0ms preprocess, 88.4ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 75.6ms\n",
      "Speed: 2.5ms preprocess, 75.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 101.3ms\n",
      "Speed: 2.0ms preprocess, 101.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tv, 1 laptop, 93.7ms\n",
      "Speed: 2.5ms preprocess, 93.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 71.8ms\n",
      "Speed: 1.5ms preprocess, 71.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cake, 1 laptop, 70.7ms\n",
      "Speed: 4.0ms preprocess, 70.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tv, 78.6ms\n",
      "Speed: 2.0ms preprocess, 78.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 75.2ms\n",
      "Speed: 1.0ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 74.5ms\n",
      "Speed: 4.1ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tv, 70.6ms\n",
      "Speed: 3.1ms preprocess, 70.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tv, 77.8ms\n",
      "Speed: 2.0ms preprocess, 77.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 75.4ms\n",
      "Speed: 2.3ms preprocess, 75.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 1 laptop, 81.7ms\n",
      "Speed: 3.0ms preprocess, 81.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.1ms\n",
      "Speed: 3.0ms preprocess, 77.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tv, 76.4ms\n",
      "Speed: 2.0ms preprocess, 76.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.6ms\n",
      "Speed: 4.4ms preprocess, 74.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 2 tvs, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tv, 71.8ms\n",
      "Speed: 3.7ms preprocess, 71.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.2ms\n",
      "Speed: 4.1ms preprocess, 69.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tv, 74.5ms\n",
      "Speed: 2.0ms preprocess, 74.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 83.8ms\n",
      "Speed: 2.0ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 tv, 75.4ms\n",
      "Speed: 2.0ms preprocess, 75.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 laptops, 73.8ms\n",
      "Speed: 3.5ms preprocess, 73.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 79.4ms\n",
      "Speed: 2.0ms preprocess, 79.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 2 laptops, 74.6ms\n",
      "Speed: 1.0ms preprocess, 74.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 1 laptop, 67.9ms\n",
      "Speed: 4.1ms preprocess, 67.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 76.4ms\n",
      "Speed: 2.5ms preprocess, 76.4ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 73.9ms\n",
      "Speed: 2.0ms preprocess, 73.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 laptops, 71.3ms\n",
      "Speed: 3.0ms preprocess, 71.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.4ms\n",
      "Speed: 3.5ms preprocess, 75.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 72.3ms\n",
      "Speed: 3.5ms preprocess, 72.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.0ms\n",
      "Speed: 3.5ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 71.8ms\n",
      "Speed: 2.0ms preprocess, 71.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 70.8ms\n",
      "Speed: 2.0ms preprocess, 70.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tv, 1 laptop, 79.4ms\n",
      "Speed: 2.0ms preprocess, 79.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 94.4ms\n",
      "Speed: 5.8ms preprocess, 94.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 laptops, 78.8ms\n",
      "Speed: 2.5ms preprocess, 78.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 tv, 67.2ms\n",
      "Speed: 2.0ms preprocess, 67.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 laptop, 75.3ms\n",
      "Speed: 1.0ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 laptop, 75.6ms\n",
      "Speed: 2.0ms preprocess, 75.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 74.2ms\n",
      "Speed: 3.0ms preprocess, 74.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 90.0ms\n",
      "Speed: 2.0ms preprocess, 90.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 78.1ms\n",
      "Speed: 3.0ms preprocess, 78.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.7ms\n",
      "Speed: 3.0ms preprocess, 79.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.6ms\n",
      "Speed: 2.0ms preprocess, 74.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 79.9ms\n",
      "Speed: 2.5ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 72.2ms\n",
      "Speed: 3.2ms preprocess, 72.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 75.6ms\n",
      "Speed: 2.0ms preprocess, 75.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.3ms\n",
      "Speed: 2.0ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 85.7ms\n",
      "Speed: 2.1ms preprocess, 85.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 laptop, 82.0ms\n",
      "Speed: 4.0ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 75.6ms\n",
      "Speed: 3.0ms preprocess, 75.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 80.1ms\n",
      "Speed: 2.0ms preprocess, 80.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.6ms\n",
      "Speed: 4.0ms preprocess, 78.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.0ms\n",
      "Speed: 2.1ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 77.6ms\n",
      "Speed: 1.5ms preprocess, 77.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.9ms\n",
      "Speed: 2.0ms preprocess, 80.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 81.4ms\n",
      "Speed: 2.0ms preprocess, 81.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.8ms\n",
      "Speed: 2.5ms preprocess, 81.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 88.2ms\n",
      "Speed: 1.6ms preprocess, 88.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.3ms\n",
      "Speed: 1.0ms preprocess, 85.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 85.0ms\n",
      "Speed: 4.0ms preprocess, 85.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 84.0ms\n",
      "Speed: 3.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 100.6ms\n",
      "Speed: 2.5ms preprocess, 100.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.9ms\n",
      "Speed: 3.5ms preprocess, 79.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 75.4ms\n",
      "Speed: 2.0ms preprocess, 75.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.4ms\n",
      "Speed: 3.5ms preprocess, 74.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 76.3ms\n",
      "Speed: 2.1ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 99.1ms\n",
      "Speed: 2.2ms preprocess, 99.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 73.6ms\n",
      "Speed: 2.5ms preprocess, 73.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 69.0ms\n",
      "Speed: 2.0ms preprocess, 69.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 77.3ms\n",
      "Speed: 2.6ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 78.1ms\n",
      "Speed: 2.0ms preprocess, 78.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 83.7ms\n",
      "Speed: 3.7ms preprocess, 83.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.0ms\n",
      "Speed: 2.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 77.9ms\n",
      "Speed: 3.5ms preprocess, 77.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 cell phones, 81.6ms\n",
      "Speed: 2.0ms preprocess, 81.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 76.5ms\n",
      "Speed: 4.0ms preprocess, 76.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 75.3ms\n",
      "Speed: 3.5ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cell phones, 77.3ms\n",
      "Speed: 2.5ms preprocess, 77.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 83.7ms\n",
      "Speed: 2.0ms preprocess, 83.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 75.2ms\n",
      "Speed: 3.5ms preprocess, 75.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 81.1ms\n",
      "Speed: 2.0ms preprocess, 81.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 81.3ms\n",
      "Speed: 2.0ms preprocess, 81.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 laptop, 1 book, 80.6ms\n",
      "Speed: 2.0ms preprocess, 80.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 book, 83.8ms\n",
      "Speed: 3.5ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 1 book, 85.0ms\n",
      "Speed: 2.7ms preprocess, 85.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 laptop, 1 cell phone, 1 book, 79.4ms\n",
      "Speed: 3.2ms preprocess, 79.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 laptop, 1 cell phone, 1 book, 83.0ms\n",
      "Speed: 2.0ms preprocess, 83.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 81.4ms\n",
      "Speed: 2.0ms preprocess, 81.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.7ms\n",
      "Speed: 1.5ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.8ms\n",
      "Speed: 4.2ms preprocess, 74.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 70.8ms\n",
      "Speed: 2.0ms preprocess, 70.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.5ms\n",
      "Speed: 2.0ms preprocess, 76.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 78.0ms\n",
      "Speed: 1.0ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 couch, 90.7ms\n",
      "Speed: 2.2ms preprocess, 90.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 79.5ms\n",
      "Speed: 2.0ms preprocess, 79.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 75.3ms\n",
      "Speed: 3.6ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 77.3ms\n",
      "Speed: 2.0ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 77.3ms\n",
      "Speed: 3.5ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 71.4ms\n",
      "Speed: 3.0ms preprocess, 71.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 73.1ms\n",
      "Speed: 2.5ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 85.7ms\n",
      "Speed: 4.6ms preprocess, 85.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 71.0ms\n",
      "Speed: 3.0ms preprocess, 71.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 73.2ms\n",
      "Speed: 3.5ms preprocess, 73.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 68.6ms\n",
      "Speed: 2.5ms preprocess, 68.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 1 remote, 71.7ms\n",
      "Speed: 2.0ms preprocess, 71.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 couchs, 74.2ms\n",
      "Speed: 2.0ms preprocess, 74.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 73.4ms\n",
      "Speed: 2.0ms preprocess, 73.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 79.4ms\n",
      "Speed: 2.0ms preprocess, 79.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 73.0ms\n",
      "Speed: 2.0ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 75.4ms\n",
      "Speed: 3.0ms preprocess, 75.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 couchs, 71.7ms\n",
      "Speed: 2.5ms preprocess, 71.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 couchs, 76.6ms\n",
      "Speed: 2.0ms preprocess, 76.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 84.1ms\n",
      "Speed: 3.0ms preprocess, 84.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 68.7ms\n",
      "Speed: 2.5ms preprocess, 68.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 74.0ms\n",
      "Speed: 3.4ms preprocess, 74.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 73.1ms\n",
      "Speed: 2.0ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 75.3ms\n",
      "Speed: 2.5ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 77.9ms\n",
      "Speed: 3.0ms preprocess, 77.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 73.9ms\n",
      "Speed: 2.4ms preprocess, 73.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 couchs, 81.9ms\n",
      "Speed: 1.5ms preprocess, 81.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 77.1ms\n",
      "Speed: 1.0ms preprocess, 77.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 couchs, 81.5ms\n",
      "Speed: 3.6ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 couch, 73.1ms\n",
      "Speed: 2.0ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 75.1ms\n",
      "Speed: 2.0ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 couch, 71.7ms\n",
      "Speed: 3.3ms preprocess, 71.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 79.4ms\n",
      "Speed: 2.5ms preprocess, 79.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 78.5ms\n",
      "Speed: 1.5ms preprocess, 78.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 78.2ms\n",
      "Speed: 2.2ms preprocess, 78.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 75.8ms\n",
      "Speed: 2.0ms preprocess, 75.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 73.9ms\n",
      "Speed: 2.5ms preprocess, 73.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 74.9ms\n",
      "Speed: 2.5ms preprocess, 74.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 78.9ms\n",
      "Speed: 2.2ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 76.3ms\n",
      "Speed: 3.5ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 1 cell phone, 70.3ms\n",
      "Speed: 3.5ms preprocess, 70.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 83.6ms\n",
      "Speed: 4.9ms preprocess, 83.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 laptop, 1 cell phone, 77.1ms\n",
      "Speed: 3.0ms preprocess, 77.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 68.1ms\n",
      "Speed: 3.0ms preprocess, 68.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 cell phone, 79.5ms\n",
      "Speed: 4.0ms preprocess, 79.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 cell phone, 70.9ms\n",
      "Speed: 3.0ms preprocess, 70.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cell phone, 78.9ms\n",
      "Speed: 1.6ms preprocess, 78.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 cell phone, 79.1ms\n",
      "Speed: 2.0ms preprocess, 79.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 75.8ms\n",
      "Speed: 2.0ms preprocess, 75.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 78.3ms\n",
      "Speed: 3.0ms preprocess, 78.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 74.3ms\n",
      "Speed: 1.0ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 77.4ms\n",
      "Speed: 2.0ms preprocess, 77.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 cell phone, 74.8ms\n",
      "Speed: 3.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 cell phone, 75.6ms\n",
      "Speed: 2.5ms preprocess, 75.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 traffic light, 1 book, 77.3ms\n",
      "Speed: 3.0ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 76.0ms\n",
      "Speed: 4.5ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 83.8ms\n",
      "Speed: 4.0ms preprocess, 83.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 75.1ms\n",
      "Speed: 2.0ms preprocess, 75.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 1 teddy bear, 75.3ms\n",
      "Speed: 3.0ms preprocess, 75.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 77.1ms\n",
      "Speed: 2.5ms preprocess, 77.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 donut, 79.6ms\n",
      "Speed: 3.7ms preprocess, 79.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 76.0ms\n",
      "Speed: 2.0ms preprocess, 76.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 79.9ms\n",
      "Speed: 2.0ms preprocess, 79.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 72.7ms\n",
      "Speed: 4.0ms preprocess, 72.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 77.7ms\n",
      "Speed: 3.5ms preprocess, 77.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 84.5ms\n",
      "Speed: 2.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 donut, 1 cell phone, 81.4ms\n",
      "Speed: 4.8ms preprocess, 81.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 74.7ms\n",
      "Speed: 2.0ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 77.7ms\n",
      "Speed: 2.5ms preprocess, 77.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 pizza, 1 chair, 73.5ms\n",
      "Speed: 2.0ms preprocess, 73.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 81.9ms\n",
      "Speed: 2.0ms preprocess, 81.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 pizza, 1 chair, 100.3ms\n",
      "Speed: 2.0ms preprocess, 100.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 pizza, 1 chair, 78.8ms\n",
      "Speed: 2.5ms preprocess, 78.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 book, 82.0ms\n",
      "Speed: 2.5ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 traffic light, 1 pizza, 1 chair, 74.2ms\n",
      "Speed: 3.4ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 donut, 1 chair, 88.6ms\n",
      "Speed: 1.0ms preprocess, 88.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.0ms\n",
      "Speed: 3.6ms preprocess, 78.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 donut, 73.0ms\n",
      "Speed: 2.0ms preprocess, 73.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 donut, 73.5ms\n",
      "Speed: 2.5ms preprocess, 73.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 69.7ms\n",
      "Speed: 1.9ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 75.4ms\n",
      "Speed: 1.0ms preprocess, 75.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 79.7ms\n",
      "Speed: 2.0ms preprocess, 79.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 donut, 90.5ms\n",
      "Speed: 3.0ms preprocess, 90.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 90.5ms\n",
      "Speed: 2.0ms preprocess, 90.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 85.6ms\n",
      "Speed: 3.1ms preprocess, 85.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 cell phone, 76.8ms\n",
      "Speed: 3.5ms preprocess, 76.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 1 cell phone, 85.2ms\n",
      "Speed: 3.5ms preprocess, 85.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 1 cell phone, 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 couch, 1 cell phone, 75.5ms\n",
      "Speed: 2.0ms preprocess, 75.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 1 cell phone, 80.5ms\n",
      "Speed: 2.0ms preprocess, 80.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 1 cell phone, 69.7ms\n",
      "Speed: 2.5ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cell phones, 81.0ms\n",
      "Speed: 3.5ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 2 cell phones, 81.2ms\n",
      "Speed: 4.0ms preprocess, 81.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 1 cell phone, 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 1 cell phone, 75.9ms\n",
      "Speed: 2.0ms preprocess, 75.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 1 cell phone, 85.3ms\n",
      "Speed: 2.0ms preprocess, 85.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 cell phone, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 cell phones, 72.7ms\n",
      "Speed: 2.0ms preprocess, 72.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 2 cell phones, 75.4ms\n",
      "Speed: 2.0ms preprocess, 75.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 77.2ms\n",
      "Speed: 2.0ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 73.6ms\n",
      "Speed: 2.0ms preprocess, 73.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 70.8ms\n",
      "Speed: 2.0ms preprocess, 70.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 72.8ms\n",
      "Speed: 3.0ms preprocess, 72.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 2 couchs, 77.0ms\n",
      "Speed: 2.0ms preprocess, 77.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 84.5ms\n",
      "Speed: 3.0ms preprocess, 84.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 80.0ms\n",
      "Speed: 2.0ms preprocess, 80.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 79.0ms\n",
      "Speed: 2.0ms preprocess, 79.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 79.0ms\n",
      "Speed: 4.2ms preprocess, 79.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.3ms\n",
      "Speed: 2.5ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 72.9ms\n",
      "Speed: 2.4ms preprocess, 72.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.1ms\n",
      "Speed: 2.5ms preprocess, 73.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.7ms\n",
      "Speed: 3.0ms preprocess, 81.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.2ms\n",
      "Speed: 3.0ms preprocess, 77.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 90.8ms\n",
      "Speed: 3.0ms preprocess, 90.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 72.2ms\n",
      "Speed: 2.0ms preprocess, 72.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.8ms\n",
      "Speed: 3.0ms preprocess, 73.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 82.1ms\n",
      "Speed: 1.0ms preprocess, 82.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 teddy bear, 70.6ms\n",
      "Speed: 1.0ms preprocess, 70.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.6ms\n",
      "Speed: 4.5ms preprocess, 76.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 77.6ms\n",
      "Speed: 4.0ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 80.1ms\n",
      "Speed: 3.5ms preprocess, 80.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 93.6ms\n",
      "Speed: 2.6ms preprocess, 93.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 75.6ms\n",
      "Speed: 4.0ms preprocess, 75.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 76.4ms\n",
      "Speed: 3.0ms preprocess, 76.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.0ms\n",
      "Speed: 3.0ms preprocess, 74.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 83.5ms\n",
      "Speed: 2.0ms preprocess, 83.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 66.0ms\n",
      "Speed: 3.0ms preprocess, 66.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 84.4ms\n",
      "Speed: 2.0ms preprocess, 84.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 70.2ms\n",
      "Speed: 2.0ms preprocess, 70.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 78.1ms\n",
      "Speed: 2.0ms preprocess, 78.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 74.8ms\n",
      "Speed: 2.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.8ms\n",
      "Speed: 2.9ms preprocess, 74.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 pizza, 70.1ms\n",
      "Speed: 3.0ms preprocess, 70.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 80.6ms\n",
      "Speed: 4.5ms preprocess, 80.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 73.5ms\n",
      "Speed: 2.5ms preprocess, 73.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 71.4ms\n",
      "Speed: 5.2ms preprocess, 71.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 chair, 1 couch, 73.3ms\n",
      "Speed: 3.6ms preprocess, 73.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 79.7ms\n",
      "Speed: 3.0ms preprocess, 79.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 69.7ms\n",
      "Speed: 2.5ms preprocess, 69.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 96.5ms\n",
      "Speed: 2.0ms preprocess, 96.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 91.3ms\n",
      "Speed: 3.6ms preprocess, 91.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 74.7ms\n",
      "Speed: 2.5ms preprocess, 74.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 75.0ms\n",
      "Speed: 1.7ms preprocess, 75.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 74.8ms\n",
      "Speed: 3.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 72.5ms\n",
      "Speed: 3.5ms preprocess, 72.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 74.3ms\n",
      "Speed: 3.3ms preprocess, 74.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 71.5ms\n",
      "Speed: 3.5ms preprocess, 71.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 74.1ms\n",
      "Speed: 3.0ms preprocess, 74.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 74.6ms\n",
      "Speed: 4.3ms preprocess, 74.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 76.1ms\n",
      "Speed: 5.1ms preprocess, 76.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 87.2ms\n",
      "Speed: 3.5ms preprocess, 87.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 73.6ms\n",
      "Speed: 3.5ms preprocess, 73.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 73.0ms\n",
      "Speed: 2.0ms preprocess, 73.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 72.1ms\n",
      "Speed: 1.5ms preprocess, 72.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 couch, 75.6ms\n",
      "Speed: 4.0ms preprocess, 75.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 69.4ms\n",
      "Speed: 4.2ms preprocess, 69.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 couch, 82.6ms\n",
      "Speed: 4.4ms preprocess, 82.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 83.4ms\n",
      "Speed: 2.0ms preprocess, 83.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 giraffe, 79.1ms\n",
      "Speed: 2.5ms preprocess, 79.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 73.6ms\n",
      "Speed: 3.0ms preprocess, 73.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 80.3ms\n",
      "Speed: 2.0ms preprocess, 80.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 couch, 78.4ms\n",
      "Speed: 2.0ms preprocess, 78.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 couch, 77.5ms\n",
      "Speed: 3.0ms preprocess, 77.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 couch, 77.3ms\n",
      "Speed: 3.0ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 couch, 73.9ms\n",
      "Speed: 4.4ms preprocess, 73.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 couch, 71.5ms\n",
      "Speed: 3.0ms preprocess, 71.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 couch, 80.1ms\n",
      "Speed: 3.1ms preprocess, 80.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 95.1ms\n",
      "Speed: 2.7ms preprocess, 95.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 1 couch, 75.4ms\n",
      "Speed: 3.2ms preprocess, 75.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 1 couch, 76.2ms\n",
      "Speed: 2.5ms preprocess, 76.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 1 couch, 74.4ms\n",
      "Speed: 2.0ms preprocess, 74.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 74.2ms\n",
      "Speed: 2.5ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 79.7ms\n",
      "Speed: 2.0ms preprocess, 79.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 couch, 100.8ms\n",
      "Speed: 9.1ms preprocess, 100.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 73.3ms\n",
      "Speed: 3.0ms preprocess, 73.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 1 couch, 78.5ms\n",
      "Speed: 2.4ms preprocess, 78.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 1 couch, 76.6ms\n",
      "Speed: 3.5ms preprocess, 76.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 76.7ms\n",
      "Speed: 2.5ms preprocess, 76.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 72.7ms\n",
      "Speed: 2.0ms preprocess, 72.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 couch, 78.1ms\n",
      "Speed: 2.0ms preprocess, 78.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 71.8ms\n",
      "Speed: 4.0ms preprocess, 71.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 couch, 82.1ms\n",
      "Speed: 2.0ms preprocess, 82.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 1 couch, 81.9ms\n",
      "Speed: 2.0ms preprocess, 81.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 82.6ms\n",
      "Speed: 1.0ms preprocess, 82.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 78.4ms\n",
      "Speed: 2.0ms preprocess, 78.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 78.2ms\n",
      "Speed: 1.0ms preprocess, 78.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.2ms\n",
      "Speed: 2.5ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 73.6ms\n",
      "Speed: 2.0ms preprocess, 73.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 74.6ms\n",
      "Speed: 2.5ms preprocess, 74.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 68.4ms\n",
      "Speed: 3.0ms preprocess, 68.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 80.0ms\n",
      "Speed: 3.5ms preprocess, 80.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 86.2ms\n",
      "Speed: 4.0ms preprocess, 86.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.2ms\n",
      "Speed: 2.0ms preprocess, 74.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 78.8ms\n",
      "Speed: 2.0ms preprocess, 78.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.3ms\n",
      "Speed: 1.5ms preprocess, 76.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 82.4ms\n",
      "Speed: 2.5ms preprocess, 82.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 88.9ms\n",
      "Speed: 2.0ms preprocess, 88.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 71.0ms\n",
      "Speed: 2.0ms preprocess, 71.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.3ms\n",
      "Speed: 2.0ms preprocess, 79.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 73.8ms\n",
      "Speed: 2.0ms preprocess, 73.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.8ms\n",
      "Speed: 2.0ms preprocess, 74.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.3ms\n",
      "Speed: 2.5ms preprocess, 78.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 70.7ms\n",
      "Speed: 2.0ms preprocess, 70.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 cup, 71.6ms\n",
      "Speed: 1.0ms preprocess, 71.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.3ms\n",
      "Speed: 2.5ms preprocess, 77.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 dog, 1 giraffe, 77.6ms\n",
      "Speed: 3.0ms preprocess, 77.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 106.7ms\n",
      "Speed: 2.0ms preprocess, 106.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 giraffe, 1 wine glass, 1 cup, 70.0ms\n",
      "Speed: 3.5ms preprocess, 70.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 72.9ms\n",
      "Speed: 4.0ms preprocess, 72.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 78.8ms\n",
      "Speed: 2.5ms preprocess, 78.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.3ms\n",
      "Speed: 2.0ms preprocess, 74.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 giraffe, 69.9ms\n",
      "Speed: 2.5ms preprocess, 69.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 79.7ms\n",
      "Speed: 1.5ms preprocess, 79.7ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 82.3ms\n",
      "Speed: 2.3ms preprocess, 82.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 78.6ms\n",
      "Speed: 2.0ms preprocess, 78.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 75.9ms\n",
      "Speed: 3.5ms preprocess, 75.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 giraffe, 71.9ms\n",
      "Speed: 3.0ms preprocess, 71.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 giraffe, 69.5ms\n",
      "Speed: 2.5ms preprocess, 69.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 71.2ms\n",
      "Speed: 2.0ms preprocess, 71.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 75.0ms\n",
      "Speed: 2.0ms preprocess, 75.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 74.1ms\n",
      "Speed: 2.5ms preprocess, 74.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 76.2ms\n",
      "Speed: 4.0ms preprocess, 76.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.0ms\n",
      "Speed: 2.0ms preprocess, 81.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 84.0ms\n",
      "Speed: 2.0ms preprocess, 84.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 82.9ms\n",
      "Speed: 2.0ms preprocess, 82.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 81.4ms\n",
      "Speed: 2.1ms preprocess, 81.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 82.3ms\n",
      "Speed: 2.3ms preprocess, 82.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 81.8ms\n",
      "Speed: 3.4ms preprocess, 81.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 72.4ms\n",
      "Speed: 2.0ms preprocess, 72.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.1ms\n",
      "Speed: 2.5ms preprocess, 77.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 69.3ms\n",
      "Speed: 2.0ms preprocess, 69.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 79.2ms\n",
      "Speed: 2.5ms preprocess, 79.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 78.5ms\n",
      "Speed: 3.0ms preprocess, 78.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 77.2ms\n",
      "Speed: 3.5ms preprocess, 77.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 77.4ms\n",
      "Speed: 3.0ms preprocess, 77.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 71.4ms\n",
      "Speed: 2.0ms preprocess, 71.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 77.9ms\n",
      "Speed: 2.0ms preprocess, 77.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 70.3ms\n",
      "Speed: 1.0ms preprocess, 70.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 88.7ms\n",
      "Speed: 2.5ms preprocess, 88.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 94.3ms\n",
      "Speed: 3.0ms preprocess, 94.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 74.3ms\n",
      "Speed: 4.0ms preprocess, 74.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 71.2ms\n",
      "Speed: 2.4ms preprocess, 71.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 74.7ms\n",
      "Speed: 2.5ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 81.7ms\n",
      "Speed: 1.5ms preprocess, 81.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 chair, 1 couch, 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 74.2ms\n",
      "Speed: 1.5ms preprocess, 74.2ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.9ms\n",
      "Speed: 2.0ms preprocess, 74.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 1 couch, 74.1ms\n",
      "Speed: 3.0ms preprocess, 74.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 chair, 76.2ms\n",
      "Speed: 3.2ms preprocess, 76.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 giraffe, 76.9ms\n",
      "Speed: 2.0ms preprocess, 76.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 73.4ms\n",
      "Speed: 2.5ms preprocess, 73.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 76.8ms\n",
      "Speed: 1.0ms preprocess, 76.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 couch, 77.3ms\n",
      "Speed: 3.0ms preprocess, 77.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 89.6ms\n",
      "Speed: 1.0ms preprocess, 89.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 86.2ms\n",
      "Speed: 2.5ms preprocess, 86.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 74.1ms\n",
      "Speed: 2.5ms preprocess, 74.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 chair, 78.3ms\n",
      "Speed: 2.0ms preprocess, 78.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 74.7ms\n",
      "Speed: 3.0ms preprocess, 74.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 giraffe, 82.7ms\n",
      "Speed: 3.0ms preprocess, 82.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 1 giraffe, 82.6ms\n",
      "Speed: 2.5ms preprocess, 82.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 giraffe, 81.4ms\n",
      "Speed: 4.4ms preprocess, 81.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 88.7ms\n",
      "Speed: 4.8ms preprocess, 88.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 2 couchs, 98.3ms\n",
      "Speed: 2.0ms preprocess, 98.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 1 chair, 81.5ms\n",
      "Speed: 2.5ms preprocess, 81.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 79.8ms\n",
      "Speed: 2.5ms preprocess, 79.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 77.7ms\n",
      "Speed: 2.0ms preprocess, 77.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 74.2ms\n",
      "Speed: 2.4ms preprocess, 74.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "from ultralytics import YOLO  # Importar YOLO de Ultralytics\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de Imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "\n",
    "        # Cargar el modelo YOLOv8\n",
    "        self.model = YOLO('yolov8n.pt')  # Cargar el modelo YOLOv8 Nano\n",
    "        self.clases = self.model.names  # Obtener los nombres de las clases\n",
    "\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.logo_imagen_tk = None\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Descargar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.mostrar_tutorial()\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def mostrar_tutorial(self):\n",
    "        self.tutorial = tk.Toplevel(self.root)\n",
    "        self.tutorial.title(\"Tutorial\")\n",
    "        self.tutorial.geometry(\"800x600\")  # Tamaño de la ventana del tutorial\n",
    "        self.tutorial.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        tutorial_text = \"\"\"\n",
    "        Bienvenido a la aplicación de detección de imágenes.\n",
    "\n",
    "        1. Abrir Cámara: Inicia la cámara para la detección.\n",
    "        2. Detectar Objetos: Activa la detección de objetos en la cámara.\n",
    "        3. Tomar Foto: Captura una imagen de la cámara.\n",
    "        4. Grabar Video: Inicia o detiene la grabación de video.\n",
    "        5. Descargar Historial: Guarda el historial de detecciones en un archivo.\n",
    "        6. Activar Voz: Anuncia los objetos detectados.\n",
    "        7. Activar Alarma: Reproduce una alarma si se detectan objetos peligrosos.\n",
    "        8. Salir: Cierra la aplicación.\n",
    "\n",
    "        Presiona 'Saltar Tutorial' para omitir este tutorial.\n",
    "        \"\"\"\n",
    "        \n",
    "        label_tutorial = tk.Label(self.tutorial, text=tutorial_text, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        label_tutorial.pack(pady=10)\n",
    "\n",
    "        boton_saltar = tk.Button(self.tutorial, text=\"Saltar Tutorial\", command=self.saltar_tutorial,\n",
    "                                  bg=\"#FFC107\", fg=\"black\", font=(\"Arial\", 12))\n",
    "        boton_saltar.pack(pady=20)\n",
    "\n",
    "    def saltar_tutorial(self):\n",
    "        self.tutorial.destroy()\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            objetos_detectados = set()  # Para almacenar objetos detectados\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                # Usar el modelo YOLOv8 para la detección\n",
    "                results = self.model(frame)\n",
    "                detecciones = results[0].boxes  # Obtener las detecciones\n",
    "\n",
    "                for box in detecciones:\n",
    "                    x1, y1, x2, y2 = map(int, box.xyxy[0])  # Coordenadas de la caja\n",
    "                    conf = box.conf[0]  # Confianza\n",
    "                    cls = int(box.cls[0])  # Clase\n",
    "\n",
    "                    label = self.clases[cls]  # Obtener el nombre de la clase\n",
    "                    objetos_detectados.add(label)  # Agregar a la lista de objetos detectados\n",
    "\n",
    "                    # Dibujar la caja en la imagen\n",
    "                    color = (0, 255, 0)  # Verde por defecto\n",
    "                    if label in [\"cuchillo\", \"pistola\"]:  # Cambiar a rojo si es un objeto peligroso\n",
    "                        color = (255, 0, 0)  # Rojo para objetos peligrosos\n",
    "                        current_time = time.time()\n",
    "                        if self.alarma_activar and (current_time - self.last_alert_time > 3):\n",
    "                            self.reproducir_alerta()\n",
    "                            self.last_alert_time = current_time\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                    cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Actualizar el historial de objetos detectados\n",
    "            if objetos_detectados:\n",
    "                self.agregar_historial(f\"Objetos detectados: {', '.join(objetos_detectados)}\")\n",
    "                self.objetos_para_anunciar.update(objetos_detectados)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar and self.voz_activar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            # Detener el hilo de video\n",
    "            if self.thread is not None:\n",
    "                self.thread.join(timeout=1)  # Espera un segundo para que el hilo termine\n",
    "            \n",
    "            # Liberar la cámara\n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            # Actualizar el estado de los botones\n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.agregar_historial(\"Foto tomada\")\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.agregar_historial(\"Grabación de video iniciada\")\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.agregar_historial(\"Grabación de video detenida\")\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.boton_voz.config(text=f\"{estado.capitalize()} Voz\")\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.boton_alarma.config(text=f\"{estado.capitalize()} Alarma\")\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        if len(self.historial_detecciones) > 50:  # Limitar el tamaño del historial\n",
    "            self.historial_detecciones.pop(0)\n",
    "        \n",
    "        # Actualizar el historial en el Text\n",
    "        self.text_historial.config(state=tk.NORMAL)  # Habilitar el Text para la edición\n",
    "        self.text_historial.delete(1.0, tk.END)  # Limpiar el Text\n",
    "        self.text_historial.insert(tk.END, \"\\n\".join(self.historial_detecciones))  # Agregar nuevo texto\n",
    "        self.text_historial.config(state=tk.DISABLED)  # Deshabilitar el Text para evitar ediciones\n",
    "        self.text_historial.yview_moveto(1)  # Desplazar hacia abajo\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        archivo = filedialog.asksaveasfile(defaultextension=\".txt\", filetypes=[(\"Archivos de texto\", \"*.txt\")])\n",
    "        if archivo:\n",
    "            for entrada in self.historial_detecciones:\n",
    "                archivo.write(entrada + \"\\n\")\n",
    "            archivo.close()\n",
    "            messagebox.showinfo(\"Éxito\", \"Historial descargado correctamente.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()  # Asegurarse de que se cierre la cámara\n",
    "        self.root.quit()  # Cerrar la aplicación\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1200x1100\")  # Establecer un tamaño fijo para la ventana\n",
    "root.resizable(False, False)  # Deshabilitar la opción de maximizar\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd814ba-f711-43cd-91dc-1833329e6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb1d25e-cc29-453d-8b57-f3e80afe47ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.12.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "\n",
    "        # Cargar modelo de YOLO\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        # Establecer la precisión de la red neuronal\n",
    "        self.precision = 0.85  # Valor de ejemplo, ajusta según tu modelo\n",
    "\n",
    "        self.frame_principal = tk.Frame(root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        # Etiqueta para mostrar la precisión\n",
    "        self.label_precision = tk.Label(self.frame_historial, text=f\"Precisión: {self.precision:.2f}\", bg=\"#2e2e2e\",\n",
    "                                         fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.label_precision.pack(pady=10)\n",
    "\n",
    "        self.logo_imagen_tk = None\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_foto = tk.Button(self.frame_botones, text=\"Tomar Foto\", command=self.tomar_foto, width=20,\n",
    "                                    state=tk.DISABLED, bg=\"#2196F3\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_foto.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_video = tk.Button(self.frame_botones, text=\"Grabar Video\", command=self.grabar_video, width=20,\n",
    "                                     state=tk.DISABLED, bg=\"#FF9800\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_video.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Descargar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.mostrar_tutorial()\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"El archivo {logo_path} no se encuentra.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def mostrar_tutorial(self):\n",
    "        self.tutorial = tk.Toplevel(self.root)\n",
    "        self.tutorial.title(\"Tutorial\")\n",
    "        self.tutorial.geometry(\"800x300\")\n",
    "        self.tutorial.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        tutorial_text = \"\"\"\n",
    "        Bienvenido a la aplicación de detección de imágenes.\n",
    "\n",
    "        1. Abrir Cámara: Inicia la cámara para la detección.\n",
    "        2. Detectar Objetos: Activa la detección de objetos en la cámara.\n",
    "        3. Tomar Foto: Captura una imagen de la cámara.\n",
    "        4. Grabar Video: Inicia o detiene la grabación de video.\n",
    "        5. Descargar Historial: Guarda el historial de detecciones en un archivo.\n",
    "        6. Activar Voz: Anuncia los objetos detectados.\n",
    "        7. Activar Alarma: Reproduce una alarma si se detectan objetos peligrosos.\n",
    "        8. Salir: Cierra la aplicación.\n",
    "\n",
    "        Presiona 'Saltar Tutorial' para omitir este tutorial.\n",
    "        \"\"\"\n",
    "        \n",
    "        label_tutorial = tk.Label(self.tutorial, text=tutorial_text, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        label_tutorial.pack(pady=10)\n",
    "\n",
    "        boton_saltar = tk.Button(self.tutorial, text=\"Saltar Tutorial\", command=self.saltar_tutorial,\n",
    "                                  bg=\"#FFC107\", fg=\"black\", font=(\"Arial\", 12))\n",
    "        boton_saltar.pack(pady=20)\n",
    "\n",
    "    def saltar_tutorial(self):\n",
    "        self.tutorial.destroy()\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_foto.config(state=tk.NORMAL)\n",
    "            self.boton_video.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            objetos_detectados = set()\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "                self.net.setInput(blob)\n",
    "                outs = self.net.forward(self.output_layers)\n",
    "\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.6:\n",
    "                            center_x = int(detection[0] * frame.shape[1])\n",
    "                            center_y = int(detection[1] * frame.shape[0])\n",
    "                            w = int(detection[2] * frame.shape[1])\n",
    "                            h = int(detection[3] * frame.shape[0])\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "\n",
    "                indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "                if len(indexes) > 0:\n",
    "                    for i in indexes.flatten():\n",
    "                        x, y, w, h = boxes[i]\n",
    "                        label = str(self.classes[class_ids[i]])\n",
    "                        objetos_detectados.add(label)\n",
    "                        color = (0, 255, 0)\n",
    "                        if label in [\"knife\", \"pistol\"]:\n",
    "                            color = (255, 0, 0)\n",
    "                            current_time = time.time()\n",
    "                            if self.alarma_activar and (current_time - self.last_alert_time > 3):\n",
    "                                self.reproducir_alerta()\n",
    "                                self.last_alert_time = current_time\n",
    "                        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "                        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            if objetos_detectados:\n",
    "                self.agregar_historial(f\"Objetos detectados: {', '.join(objetos_detectados)}\")\n",
    "                self.objetos_para_anunciar.update(objetos_detectados)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar and self.voz_activar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            if self.thread is not None:\n",
    "                self.thread.join(timeout=1)\n",
    "            \n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_foto.config(state=tk.DISABLED)\n",
    "            self.boton_video.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.agregar_historial(\"Foto tomada\")\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.agregar_historial(\"Grabación de video iniciada\")\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.agregar_historial(\"Grabación de video detenida\")\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.boton_voz.config(text=f\"{estado.capitalize()} Voz\")\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.boton_alarma.config(text=f\"{estado.capitalize()} Alarma\")\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        if len(self.historial_detecciones) > 50:\n",
    "            self.historial_detecciones.pop(0)\n",
    "        \n",
    "        self.text_historial.config(state=tk.NORMAL)\n",
    "        self.text_historial.delete(1.0, tk.END)\n",
    "        self.text_historial.insert(tk.END, \"\\n\".join(self.historial_detecciones))\n",
    "        self.text_historial.config(state=tk.DISABLED)\n",
    "        self.text_historial.yview_moveto(1)\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        archivo = filedialog.asksaveasfile(defaultextension=\".txt\", filetypes=[(\"Text files\", \"*.txt\")])\n",
    "        if archivo:\n",
    "            for entrada in self.historial_detecciones:\n",
    "                archivo.write(entrada + \"\\n\")\n",
    "            archivo.close()\n",
    "            messagebox.showinfo(\"Éxito\", \"Historial descargado correctamente.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()\n",
    "        self.root.quit()\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1200x1100\")\n",
    "root.resizable(False, False)\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83e19093-7167-4cb4-aa77-427ee1129fe7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 56 (3021758568.py, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 57\u001b[1;36m\u001b[0m\n\u001b[1;33m    button_configurations = [\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 56\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import datetime\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.setup_ui()\n",
    "        self.initialize_variables()\n",
    "        self.load_model()\n",
    "        self.load_logo()\n",
    "        self.show_tutorial()\n",
    "\n",
    "    def setup_ui(self):\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.frame_principal = tk.Frame(self.root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.create_buttons()\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "    def create_buttons(self):\n",
    "    button_configurations = [\n",
    "        (\"Abrir Cámara\", self.abrir_camara, \"4CAF50\"),\n",
    "        (\"Cerrar Cámara\", self.cerrar_camara, \"F44336\", tk.DISABLED),\n",
    "        (\"Tomar Foto\", self.tomar_foto, \"2196F3\", tk.DISABLED),\n",
    "        (\"Grabar Video\", self.grabar_video, \"FF9800\", tk.DISABLED),\n",
    "        (\"Detectar Objetos\", self.toggle_deteccion, \"9C27B0\", tk.DISABLED),\n",
    "        (\"Activar Voz\", self.toggle_voz, \"9C27B0\", tk.DISABLED),\n",
    "        (\"Activar Alarma\", self.toggle_alarma, \"9C27B0\", tk.DISABLED),\n",
    "        (\"Descargar Historial\", self.descargar_historial, \"9C27B0\", tk.DISABLED),\n",
    "        (\"Salir\", self.salir, \"9E9E9E\")\n",
    "    ]\n",
    "\n",
    "    for idx, config in enumerate(button_configurations):\n",
    "        text, command, color = config[:3]\n",
    "        state = config[3] if len(config) > 3 else tk.NORMAL\n",
    "        button = tk.Button(self.frame_botones, text=text, command=command, width=20,\n",
    "                           bg=f\"#{color}\", fg=\"white\", font=(\"Arial\", 12), state=state)\n",
    "        button.grid(row=idx // 2, column=idx % 2, padx=10, pady=10)\n",
    "\n",
    "    def initialize_variables(self):\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.thread = None\n",
    "        self.grabando_video = False\n",
    "        self.video_writer = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "\n",
    "    def load_model(self):\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    def load_logo(self):\n",
    "        logo_path = \"Logo1.png\"\n",
    "        if os.path.exists(logo_path):\n",
    "            self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "            self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "            self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "            self.label_logo.pack(pady=20)\n",
    "        else:\n",
    "            print(f\"El archivo {logo_path} no se encuentra.\")\n",
    "\n",
    "    def show_tutorial(self):\n",
    "        self.tutorial = tk.Toplevel(self.root)\n",
    "        self.tutorial.title(\"Tutorial\")\n",
    "        self.tutorial.geometry(\"800x450\")\n",
    "        self.tutorial.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        tutorial_text = \"\"\"\n",
    "        Bienvenido a la aplicación de detección de imágenes.\n",
    "\n",
    "        1. Abrir Cámara: Iniciara la cámara para la detección.\n",
    "        2. Detectar Objetos: Activara la detección de objetos en la cámara.\n",
    "        3. Tomar Foto: Captura una imagen de la cámara.\n",
    "        4. Grabar Video: Iniciara o detendr la grabación de video.\n",
    "        5. Descargar Historial: Guardara el historial de detecciones en un archivo.\n",
    "        6. Activar Voz: Anunciara los objetos detectados y si esta activado desactivara la voz.\n",
    "        7. Activar Alarma: Reproducira una alarma si se detectan objetos peligrosos.\n",
    "        8. Salir: Cierra la aplicación.\n",
    "\n",
    "        Presiona 'Saltar Tutorial' para omitir este tutorial.\n",
    "        \"\"\"\n",
    "\n",
    "        label_tutorial = tk.Label(self.tutorial, text=tutorial_text, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        label_tutorial.pack(pady=10)\n",
    "\n",
    "        boton_saltar = tk.Button(self.tutorial, text=\"Saltar Tutorial\", command=self.saltar_tutorial,\n",
    "                                  bg=\"#FFC107\", fg=\"black\", font=(\"Arial\", 12))\n",
    "        boton_saltar.pack(pady=20)\n",
    "\n",
    "    def saltar_tutorial(self):\n",
    "        self.tutorial.destroy()\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(0)\n",
    "            if not self.cap.isOpened():\n",
    "                self.cap = cv2.VideoCapture(1)\n",
    "\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.update_button_states()\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread = Thread(target=self.actualizar_video)\n",
    "            self.thread.daemon = True\n",
    "            self.thread.start()\n",
    "\n",
    "            self.thread_anunciar = Thread(target=self.anunciar_objetos_detectados)\n",
    "            self.thread_anunciar.daemon = True\n",
    "            self.thread_anunciar.start()\n",
    "\n",
    "    def update_button_states(self):\n",
    "        states = {\n",
    "            \"abrir\": tk.DISABLED,\n",
    "            \"cerrar\": tk.NORMAL,\n",
    "            \"foto\": tk.NORMAL,\n",
    "            \"video\": tk.NORMAL,\n",
    "            \"deteccion\": tk.NORMAL,\n",
    "            \"voz\": tk.NORMAL,\n",
    "            \"alarma\": tk.NORMAL,\n",
    "            \"descargar\": tk.NORMAL,\n",
    "        }\n",
    "        self.boton_abrir.config(state=states[\"abrir\"])\n",
    "        self.boton_cerrar.config(state=states[\"cerrar\"])\n",
    "        self.boton_foto.config(state=states[\"foto\"])\n",
    "        self.boton_video.config(state=states[\"video\"])\n",
    "        self.boton_deteccion.config(state=states[\"deteccion\"])\n",
    "        self.boton_voz.config(state=states[\"voz\"])\n",
    "        self.boton_alarma.config(state=states[\"alarma\"])\n",
    "        self.boton_descargar.config(state=states[\"descargar\"])\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            objetos_detectados = set()\n",
    "            if self.detectando_objetos:\n",
    "                self.detect_objects(frame, objetos_detectados)\n",
    "\n",
    "            if objetos_detectados:\n",
    "                self.agregar_historial(f\"Objetos detectados: {', '.join(objetos_detectados)}\")\n",
    "                self.objetos_para_anunciar.update(objetos_detectados)\n",
    "\n",
    "            self.display_frame(frame)\n",
    "\n",
    "    def detect_objects(self, frame, objetos_detectados):\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        outs = self.net.forward(self.output_layers)\n",
    "\n",
    "        class_ids, confidences, boxes = [], [], []\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.6:\n",
    "                    center_x = int(detection[0] * frame.shape[1])\n",
    "                    center_y = int(detection[1] * frame.shape[0])\n",
    "                    w = int(detection[2] * frame.shape[1])\n",
    "                    h = int(detection[3] * frame.shape[0])\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "        self.draw_boxes(frame, indexes, boxes, class_ids, objetos_detectados)\n",
    "\n",
    "    def draw_boxes(self, frame, indexes, boxes, class_ids, objetos_detectados):\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(self.classes[class_ids[i]])\n",
    "            objetos_detectados.add(label)\n",
    "            color = (0, 255, 0) if label not in [\"knife\", \"pistol\"] else (255, 0, 0)\n",
    "            if color == (255, 0, 0):\n",
    "                self.check_alarm()\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "    def check_alarm(self):\n",
    "        current_time = time.time()\n",
    "        if self.alarma_activar and (current_time - self.last_alert_time > 3):\n",
    "            self.reproducir_alerta()\n",
    "            self.last_alert_time = current_time\n",
    "\n",
    "    def display_frame(self, frame):\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_pil = Image.fromarray(frame_rgb)\n",
    "        frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "        self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "        self.canvas.image = frame_tk\n",
    "\n",
    "    def anunciar_objetos_detectados(self):\n",
    "        while True:\n",
    "            if self.objetos_para_anunciar and self.voz_activar:\n",
    "                objetos = \", \".join(self.objetos_para_anunciar)\n",
    "                self.engine.say(f\"Objetos detectados: {objetos}\")\n",
    "                self.engine.runAndWait()\n",
    "                self.objetos_para_anunciar.clear()\n",
    "            time.sleep(1)\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            if self.thread is not None:\n",
    "                self.thread.join(timeout=1)\n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            self.update_button_states()\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def tomar_foto(self):\n",
    "        if self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                photo_filename = f\"foto_{timestamp}.jpg\"\n",
    "                cv2.imwrite(photo_filename, frame)\n",
    "                self.agregar_historial(\"Foto tomada\")\n",
    "                messagebox.showinfo(\"Foto tomada\", f\"La foto se guardó como {photo_filename}.\")\n",
    "\n",
    "    def grabar_video(self):\n",
    "        if self.camara_activa:\n",
    "            self.grabando_video = not self.grabando_video\n",
    "\n",
    "            if self.grabando_video:\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                video_filename = f\"video_{timestamp}.avi\"\n",
    "                self.video_writer = cv2.VideoWriter(video_filename, cv2.VideoWriter_fourcc(*'XVID'), 20.0, (640, 480))\n",
    "                self.boton_video.config(text=\"Detener Video\")\n",
    "                self.agregar_historial(\"Grabación de video iniciada\")\n",
    "            else:\n",
    "                self.video_writer.release()\n",
    "                self.boton_video.config(text=\"Grabar Video\")\n",
    "                self.agregar_historial(\"Grabación de video detenida\")\n",
    "                messagebox.showinfo(\"Grabación detenida\", \"La grabación de video ha sido detenida.\")\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.boton_voz.config(text=f\"{estado.capitalize()} Voz\")\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.boton_alarma.config(text=f\"{estado.capitalize()} Alarma\")\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        if len(self.historial_detecciones) > 50:\n",
    "            self.historial_detecciones.pop(0)\n",
    "        \n",
    "        # Actualizar el historial en el Text\n",
    "        self.text_historial.config(state=tk.NORMAL)\n",
    "        self.text_historial.delete(1.0, tk.END)\n",
    "        self.text_historial.insert(tk.END, \"\\n\".join(self.historial_detecciones))\n",
    "        self.text_historial.config(state=tk.DISABLED)\n",
    "        self.text_historial.yview_moveto(1)\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        try:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")\n",
    "            pygame.mixer.music.play()\n",
    "        except Exception as e:\n",
    "            print(f\"Error al reproducir el sonido: {e}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        archivo = filedialog.asksaveasfile(defaultextension=\".txt\", filetypes=[(\"Text files\", \"*.txt\")])\n",
    "        if archivo:\n",
    "            with open(archivo.name, \"w\") as f:\n",
    "                for entrada in self.historial_detecciones:\n",
    "                    f.write(entrada + \"\\n\")\n",
    "            messagebox.showinfo(\"Éxito\", \"Historial descargado de manera correcta.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()\n",
    "        self.root.quit()\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1200x1100\")\n",
    "root.resizable(False, False)\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf9e67c-65b4-4cda-b790-fe9d3617f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"gun\", \"knife\", \"bat\" , \"machete\" ,\"stun gun\" ,\"pepper spray\" , \"reflective vest\" , \"first aid kit\" , \"security badge\", \"handcuffs\" , \"fire\" , \"smoke\" , \"earthquake\" , \"flood\" , \"tornado\" , \"urricane\" , \"avalanche\", \"landslide\", \"tsunami\", \"explosion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca86c6e0-666f-4284-bf34-f4c13e626e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd56284-5552-4619-aff6-31cb420b2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from datetime import datetime\n",
    "from queue import Queue\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.predicciones = []\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "        self.camara_index = 0\n",
    "        self.voice_queue = Queue()\n",
    "        self.thread_voice = Thread(target=self.process_voice_queue)\n",
    "        self.thread_voice.daemon = True\n",
    "        self.thread_voice.start()\n",
    "\n",
    "        self.modelo_entrenado = False\n",
    "        self.entrenar_modelo_ejemplo()\n",
    "\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.mostrar_tutorial()\n",
    "        self.setup_ui()\n",
    "\n",
    "    def mostrar_tutorial(self):\n",
    "        tutorial_window = tk.Toplevel(self.root)\n",
    "        tutorial_window.title(\"Tutorial\")\n",
    "        tutorial_window.geometry(\"400x300\")\n",
    "        tutorial_window.config(bg=\"#1a1a1a\")\n",
    "\n",
    "        titulo = tk.Label(tutorial_window, text=\"Bienvenido al Detector de Imágenes\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 16))\n",
    "        titulo.pack(pady=10)\n",
    "\n",
    "        tutorial_text = (\n",
    "            \"Esta herramienta permite detectar objetos peligrosos en tiempo real.\\n\\n\"\n",
    "            \"1. Abre la cámara.\\n\"\n",
    "            \"2. Activa la detección de objetos.\\n\"\n",
    "            \"3. Recibe alertas por voz y visuales.\\n\"\n",
    "            \"4. Cierra la cámara cuando termines.\"\n",
    "        )\n",
    "        instrucciones = tk.Label(tutorial_window, text=tutorial_text, bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        instrucciones.pack(pady=20)\n",
    "\n",
    "        boton_omitir = tk.Button(tutorial_window, text=\"Cerrar Tutorial\", command=tutorial_window.destroy, bg=\"#4CAF50\", fg=\"white\")\n",
    "        boton_omitir.pack(pady=10)\n",
    "\n",
    "        # Bloquear la ventana principal hasta que el tutorial se cierre\n",
    "        tutorial_window.protocol(\"WM_DELETE_WINDOW\", tutorial_window.destroy)\n",
    "\n",
    "    def setup_ui(self):\n",
    "        self.frame_principal = tk.Frame(self.root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Descargar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cambiar_camara = tk.Button(self.frame_botones, text=\"Cambiar Cámara\", command=self.cambiar_camara, width=20,\n",
    "                                              state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cambiar_camara.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_prediccion = tk.Button(self.frame_botones, text=\"Realizar Predicción\", command=self.mostrar_prediccion,\n",
    "                                           width=20, state=tk.DISABLED, bg=\"#009688\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_prediccion.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def hablar(self, mensaje):\n",
    "        if self.voz_activar:  # Solo agregar a la cola si la voz está activada\n",
    "            self.voice_queue.put(mensaje)\n",
    "\n",
    "    def process_voice_queue(self):\n",
    "        while True:\n",
    "            mensaje = self.voice_queue.get()\n",
    "            if self.voz_activar:  # Verificar si la voz está activada\n",
    "                self.engine.say(mensaje)\n",
    "                self.engine.runAndWait()\n",
    "\n",
    "    def entrenar_modelo_ejemplo(self):\n",
    "        X = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 1, 0], [0, 0, 0]])\n",
    "        y = np.array(['bajo', 'alto', 'medio', 'alto', 'bajo'])\n",
    "        \n",
    "        self.le = LabelEncoder()\n",
    "        y_encoded = self.le.fit_transform(y)\n",
    "        \n",
    "        self.modelo = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=5000, learning_rate_init=0.01)\n",
    "        self.modelo.fit(X, y_encoded)\n",
    "        self.modelo_entrenado = True\n",
    "\n",
    "    def predecir_peligro(self, datos):\n",
    "        if self.modelo_entrenado:\n",
    "            prediccion_encoded = self.modelo.predict([datos])\n",
    "            return self.le.inverse_transform(prediccion_encoded)[0]\n",
    "        return \"Error en el modelo\"\n",
    "\n",
    "    def generar_datos_prediccion(self):\n",
    "        if len(self.predicciones) == 0:\n",
    "            return [0, 0, 0]\n",
    "        \n",
    "        # Contar solo los objetos peligrosos detectados en la cámara\n",
    "        peligrosos = sum(1 for obj in self.predicciones if obj['label'] in [\"knife\", \"pistol\", \"scissors\"])\n",
    "        no_peligrosos = len(self.predicciones) - peligrosos\n",
    "        return [peligrosos, no_peligrosos, random.randint(0, 1)]\n",
    "\n",
    "    def mostrar_prediccion(self):\n",
    "        self.ventana_prediccion = tk.Toplevel(self.root)\n",
    "        self.ventana_prediccion.title(\"Análisis de Riesgo\")\n",
    "        self.ventana_prediccion.geometry(\"400x300\")\n",
    "        self.ventana_prediccion.config(bg=\"#1a1a1a\")\n",
    "\n",
    "        titulo = tk.Label(self.ventana_prediccion, text=\"Análisis de Riesgo en Tiempo Real\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 16))\n",
    "        titulo.pack(pady=10)\n",
    "\n",
    "        self.label_resultado = tk.Label(self.ventana_prediccion, text=\"\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 14))\n",
    "        self.label_resultado.pack(pady=10)\n",
    "\n",
    "        self.label_peligrosos = tk.Label(self.ventana_prediccion, text=\"Objetos Peligrosos: 0\", bg=\"#1a1a1a\", fg=\"red\", font=(\"Arial\", 12))\n",
    "        self.label_peligrosos.pack(pady=5)\n",
    "\n",
    "        self.label_seguros = tk.Label(self.ventana_prediccion, text=\"Objetos Seguros: 0\", bg=\"#1a1a1a\", fg=\"green\", font=(\"Arial\", 12))\n",
    "        self.label_seguros.pack(pady=5)\n",
    "\n",
    "        self.label_nivel_riesgo = tk.Label(self.ventana_prediccion, text=\"Nivel de riesgo: BAJO\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 14))\n",
    "        self.label_nivel_riesgo.pack(pady=20)\n",
    "\n",
    "        nota = tk.Label(self.ventana_prediccion, text=\"* Basado en análisis de objetos detectados y patrones históricos\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 10))\n",
    "        nota.pack(pady=5)\n",
    "\n",
    "        self.thread_actualizar_prediccion = Thread(target=self.actualizar_prediccion_en_ventana)\n",
    "        self.thread_actualizar_prediccion.daemon = True\n",
    "        self.thread_actualizar_prediccion.start()\n",
    "\n",
    "    def actualizar_prediccion_en_ventana(self):\n",
    "        contador_peligrosos = 0\n",
    "        contador_seguros = 0\n",
    "\n",
    "        while self.camara_activa and self.detectando_objetos:\n",
    "            datos_entrada = self.generar_datos_prediccion()\n",
    "            resultado = self.predecir_peligro(datos_entrada)\n",
    "\n",
    "            # Verificar si la ventana aún está abierta\n",
    "            if not self.ventana_prediccion.winfo_exists():\n",
    "                break\n",
    "\n",
    "            self.label_resultado.config(text=f\"Datos analizados: {resultado}\")\n",
    "\n",
    "            if resultado == \"alto\":\n",
    "                contador_peligrosos += 1\n",
    "                self.label_nivel_riesgo.config(text=\"Nivel de riesgo: ALTO\")\n",
    "            else:\n",
    "                contador_seguros += 1\n",
    "                self.label_nivel_riesgo.config(text=\"Nivel de riesgo: BAJO\")\n",
    "\n",
    "            self.label_peligrosos.config(text=f\"Objetos Peligrosos: {contador_peligrosos}\")\n",
    "            self.label_seguros.config(text=f\"Objetos Seguros: {contador_seguros}\")\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(self.camara_index)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "            self.boton_cambiar_camara.config(state=tk.NORMAL)\n",
    "            self.boton_prediccion.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread_video = Thread(target=self.actualizar_video)\n",
    "            self.thread_video.daemon = True\n",
    "            self.thread_video.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                self.procesar_frame(frame)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def procesar_frame(self, frame):\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        outs = self.net.forward(self.output_layers)\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.6:\n",
    "                    center_x = int(detection[0] * frame.shape[1])\n",
    "                    center_y = int(detection[1] * frame.shape[0])\n",
    "                    w = int(detection[2] * frame.shape[1])\n",
    "                    h = int(detection[3] * frame.shape[0])\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "        objetos_detectados = []\n",
    "        for i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(self.classes[class_ids[i]])\n",
    "            confidence = confidences[i] * 100\n",
    "            objetos_detectados.append({'label': label, 'confidence': confidence})\n",
    "            color = (0, 255, 0)\n",
    "            if label in [\"knife\", \"pistol\", \"scissors\"]:\n",
    "                color = (255, 0, 0)\n",
    "                self.reproducir_alerta()  # Llamar a la función de alerta\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, f\"{label} {confidence:.2f}%\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Anunciar el objeto detectado\n",
    "            if self.voz_activar and label not in self.objetos_para_anunciar:\n",
    "                self.hablar(f\"Detectado: {label}\")\n",
    "                self.objetos_para_anunciar.add(label)\n",
    "\n",
    "        self.predicciones = objetos_detectados\n",
    "        self.agregar_historial(f\"Objetos detectados: {', '.join([obj['label'] for obj in objetos_detectados])}\")\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        if self.alarma_activar:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")  # Asegúrate de tener un archivo de sonido llamado alerta.mp3\n",
    "            pygame.mixer.music.play()\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "            self.boton_cambiar_camara.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def cambiar_camara(self):\n",
    "        self.camara_index = 1 if self.camara_index == 0 else 0\n",
    "        self.cerrar_camara()\n",
    "        self.abrir_camara()\n",
    "        self.agregar_historial(f\"Cámara cambiada a {'Cámara web externa' if self.camara_index == 0 else 'Cámara de la laptop'}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        self.text_historial.config(state=tk.NORMAL)\n",
    "        self.text_historial.insert(tk.END, f\"{timestamp}: {mensaje}\\n\")\n",
    "        self.text_historial.config(state=tk.DISABLED)\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "        # Detener la voz si se desactiva la detección\n",
    "        if not self.detectando_objetos and self.voz_activar:\n",
    "            self.engine.stop()\n",
    "            self.objetos_para_anunciar.clear()\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "        # Cambiar el texto del botón\n",
    "        self.boton_voz.config(text=\"Desactivar Voz\" if self.voz_activar else \"Activar Voz\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        if self.historial_detecciones:\n",
    "            archivo = filedialog.asksaveasfilename(defaultextension=\".txt\",\n",
    "                                                    filetypes=[(\"Archivos de texto\", \"*.txt\")])\n",
    "            if archivo:\n",
    "                with open(archivo, \"w\") as f:\n",
    "                    for mensaje in self.historial_detecciones:\n",
    "                        f.write(mensaje + \"\\n\")\n",
    "                messagebox.showinfo(\"Descargar Historial\", \"Historial guardado correctamente.\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"Descargar Historial\", \"No hay historial para guardar.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()\n",
    "        self.root.quit()\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1500x1100\")\n",
    "root.resizable(False, False)\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1e267ec-9aa2-4454-89fc-efeacf0bc8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambios final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5c7c2-291f-49c3-9fb1-15eda09b1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from datetime import datetime\n",
    "from queue import Queue\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.predicciones = []\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "        self.camara_index = 0\n",
    "        self.voice_queue = Queue()\n",
    "        self.thread_voice = Thread(target=self.process_voice_queue)\n",
    "        self.thread_voice.daemon = True\n",
    "        self.thread_voice.start()\n",
    "\n",
    "        self.modelo_entrenado = False\n",
    "        self.entrenar_modelo_ejemplo()\n",
    "\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.mostrar_tutorial()\n",
    "        self.setup_ui()\n",
    "\n",
    "    def mostrar_tutorial(self):\n",
    "        tutorial_window = tk.Toplevel(self.root)\n",
    "        tutorial_window.title(\"Tutorial\")\n",
    "        tutorial_window.geometry(\"400x300\")\n",
    "        tutorial_window.config(bg=\"#1a1a1a\")\n",
    "\n",
    "        titulo = tk.Label(tutorial_window, text=\"Bienvenido al Detector de Imágenes\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 16))\n",
    "        titulo.pack(pady=10)\n",
    "\n",
    "        tutorial_text = (\n",
    "            \"Esta herramienta permite detectar objetos peligrosos en tiempo real.\\n\\n\"\n",
    "            \"1. Abre la cámara.\\n\"\n",
    "            \"2. Activa la detección de objetos.\\n\"\n",
    "            \"3. Recibe alertas por voz y visuales.\\n\"\n",
    "            \"4. Cierra la cámara cuando termines.\"\n",
    "        )\n",
    "        instrucciones = tk.Label(tutorial_window, text=tutorial_text, bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        instrucciones.pack(pady=20)\n",
    "\n",
    "        boton_omitir = tk.Button(tutorial_window, text=\"Cerrar Tutorial\", command=tutorial_window.destroy, bg=\"#4CAF50\", fg=\"white\")\n",
    "        boton_omitir.pack(pady=10)\n",
    "\n",
    "        tutorial_window.protocol(\"WM_DELETE_WINDOW\", tutorial_window.destroy)\n",
    "\n",
    "    def setup_ui(self):\n",
    "        self.frame_principal = tk.Frame(self.root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Descargar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cambiar_camara = tk.Button(self.frame_botones, text=\"Cambiar Cámara\", command=self.cambiar_camara, width=20,\n",
    "                                              state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cambiar_camara.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_prediccion = tk.Button(self.frame_botones, text=\"Realizar Predicción\", command=self.mostrar_prediccion,\n",
    "                                           width=20, state=tk.DISABLED, bg=\"#009688\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_prediccion.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def hablar(self, mensaje):\n",
    "        if self.voz_activar:  # Solo agregar a la cola si la voz está activada\n",
    "            self.voice_queue.put(mensaje)\n",
    "\n",
    "    def process_voice_queue(self):\n",
    "        while True:\n",
    "            mensaje = self.voice_queue.get()\n",
    "            if self.voz_activar:  # Verificar si la voz está activada\n",
    "                self.engine.say(mensaje)\n",
    "                self.engine.runAndWait()\n",
    "\n",
    "    def entrenar_modelo_ejemplo(self):\n",
    "        X = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 1, 0], [0, 0, 0]])\n",
    "        y = np.array(['bajo', 'alto', 'medio', 'alto', 'bajo'])\n",
    "        \n",
    "        self.le = LabelEncoder()\n",
    "        y_encoded = self.le.fit_transform(y)\n",
    "        \n",
    "        self.modelo = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=5000, learning_rate_init=0.01)\n",
    "        self.modelo.fit(X, y_encoded)\n",
    "        self.modelo_entrenado = True\n",
    "\n",
    "    def predecir_peligro(self, datos):\n",
    "        if self.modelo_entrenado:\n",
    "            prediccion_encoded = self.modelo.predict([datos])\n",
    "            return self.le.inverse_transform(prediccion_encoded)[0]\n",
    "        return \"Error en el modelo\"\n",
    "\n",
    "    def generar_datos_prediccion(self):\n",
    "        if len(self.predicciones) == 0:\n",
    "            return [0, 0, 0]\n",
    "        \n",
    "        # Contar solo los objetos peligrosos detectados en la cámara\n",
    "        peligrosos = sum(1 for obj in self.predicciones if obj['label'] in [\"knife\", \"pistol\", \"scissors\"])\n",
    "        no_peligrosos = len(self.predicciones) - peligrosos\n",
    "        return [peligrosos, no_peligrosos, random.randint(0, 1)]\n",
    "\n",
    "    def mostrar_prediccion(self):\n",
    "        self.ventana_prediccion = tk.Toplevel(self.root)\n",
    "        self.ventana_prediccion.title(\"Análisis de Riesgo\")\n",
    "        self.ventana_prediccion.geometry(\"400x300\")\n",
    "        self.ventana_prediccion.config(bg=\"#1a1a1a\")\n",
    "\n",
    "        titulo = tk.Label(self.ventana_prediccion, text=\"Análisis de Riesgo en Tiempo Real\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 16))\n",
    "        titulo.pack(pady=10)\n",
    "\n",
    "        self.label_resultado = tk.Label(self.ventana_prediccion, text=\"\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 14))\n",
    "        self.label_resultado.pack(pady=10)\n",
    "\n",
    "        self.label_peligrosos = tk.Label(self.ventana_prediccion, text=\"Objetos Peligrosos: 0\", bg=\"#1a1a1a\", fg=\"red\", font=(\"Arial\", 12))\n",
    "        self.label_peligrosos.pack(pady=5)\n",
    "\n",
    "        self.label_seguros = tk.Label(self.ventana_prediccion, text=\"Objetos Seguros: 0\", bg=\"#1a1a1a\", fg=\"green\", font=(\"Arial\", 12))\n",
    "        self.label_seguros.pack(pady=5)\n",
    "\n",
    "        self.label_nivel_riesgo = tk.Label(self.ventana_prediccion, text=\"Nivel de riesgo: BAJO\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 14))\n",
    "        self.label_nivel_riesgo.pack(pady=20)\n",
    "\n",
    "        nota = tk.Label(self.ventana_prediccion, text=\"* Basado en análisis de objetos detectados y patrones históricos\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 10))\n",
    "        nota.pack(pady=5)\n",
    "\n",
    "        self.thread_actualizar_prediccion = Thread(target=self.actualizar_prediccion_en_ventana)\n",
    "        self.thread_actualizar_prediccion.daemon = True\n",
    "        self.thread_actualizar_prediccion.start()\n",
    "\n",
    "    def actualizar_prediccion_en_ventana(self):\n",
    "        while self.camara_activa and self.detectando_objetos:\n",
    "            datos_entrada = self.generar_datos_prediccion()\n",
    "            resultado = self.predecir_peligro(datos_entrada)\n",
    "\n",
    "            # Verificar si la ventana aún está abierta\n",
    "            if not self.ventana_prediccion.winfo_exists():\n",
    "                break\n",
    "\n",
    "            # Contar objetos peligrosos y seguros\n",
    "            peligrosos = datos_entrada[0]\n",
    "            no_peligrosos = datos_entrada[1]\n",
    "\n",
    "            self.label_resultado.config(text=f\"Datos analizados: {resultado}\")\n",
    "            self.label_peligrosos.config(text=f\"Objetos Peligrosos: {peligrosos}\")\n",
    "            self.label_seguros.config(text=f\"Objetos Seguros: {no_peligrosos}\")\n",
    "\n",
    "            if resultado == \"alto\":\n",
    "                self.label_nivel_riesgo.config(text=\"Nivel de riesgo: ALTO\")\n",
    "            else:\n",
    "                self.label_nivel_riesgo.config(text=\"Nivel de riesgo: BAJO\")\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(self.camara_index)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "            self.boton_cambiar_camara.config(state=tk.NORMAL)\n",
    "            self.boton_prediccion.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread_video = Thread(target=self.actualizar_video)\n",
    "            self.thread_video.daemon = True\n",
    "            self.thread_video.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                self.procesar_frame(frame)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def procesar_frame(self, frame):\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        outs = self.net.forward(self.output_layers)\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.6:\n",
    "                    center_x = int(detection[0] * frame.shape[1])\n",
    "                    center_y = int(detection[1] * frame.shape[0])\n",
    "                    w = int(detection[2] * frame.shape[1])\n",
    "                    h = int(detection[3] * frame.shape[0])\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "        objetos_detectados = []\n",
    "        for i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(self.classes[class_ids[i]])\n",
    "            confidence = confidences[i] * 100\n",
    "            objetos_detectados.append({'label': label, 'confidence': confidence})\n",
    "            color = (0, 255, 0)\n",
    "            if label in [\"knife\", \"pistol\", \"scissors\"]:\n",
    "                color = (255, 0, 0)\n",
    "                self.reproducir_alerta()  # Llamar a la función de alerta\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, f\"{label} {confidence:.2f}%\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Anunciar el objeto detectado\n",
    "            if self.voz_activar and label not in self.objetos_para_anunciar:\n",
    "                self.hablar(f\"Detectado: {label}\")\n",
    "                self.objetos_para_anunciar.add(label)\n",
    "\n",
    "        self.predicciones = objetos_detectados\n",
    "        self.agregar_historial(f\"Objetos detectados: {', '.join([obj['label'] for obj in objetos_detectados])}\")\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        if self.alarma_activar:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")  # Asegúrate de tener un archivo de sonido llamado alerta.mp3\n",
    "            pygame.mixer.music.play()\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "            self.boton_cambiar_camara.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def cambiar_camara(self):\n",
    "        self.camara_index = 1 if self.camara_index == 0 else 0\n",
    "        self.cerrar_camara()\n",
    "        self.abrir_camara()\n",
    "        self.agregar_historial(f\"Cámara cambiada a {'Cámara web externa' if self.camara_index == 0 else 'Cámara de la laptop'}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        self.text_historial.config(state=tk.NORMAL)\n",
    "        self.text_historial.insert(tk.END, f\"{timestamp}: {mensaje}\\n\")\n",
    "        self.text_historial.config(state=tk.DISABLED)\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "        # Detener la voz si se desactiva la detección\n",
    "        if not self.detectando_objetos and self.voz_activar:\n",
    "            self.engine.stop()\n",
    "            self.objetos_para_anunciar.clear()\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "        # Cambiar el texto del botón\n",
    "        self.boton_voz.config(text=\"Desactivar Voz\" if self.voz_activar else \"Activar Voz\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        if self.historial_detecciones:\n",
    "            archivo = filedialog.asksaveasfilename(defaultextension=\".txt\",\n",
    "                                                    filetypes=[(\"Archivos de texto\", \"*.txt\")])\n",
    "            if archivo:\n",
    "                with open(archivo, \"w\") as f:\n",
    "                    for mensaje in self.historial_detecciones:\n",
    "                        f.write(mensaje + \"\\n\")\n",
    "                messagebox.showinfo(\"Descargar Historial\", \"Historial guardado correctamente.\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"Descargar Historial\", \"No hay historial para guardar.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()\n",
    "        self.root.quit()\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1500x1100\")\n",
    "root.resizable(False, False)\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968dd3c-6040-4bb0-b91f-7982346c5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox, Scrollbar, Frame, filedialog\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import pyttsx3\n",
    "import os\n",
    "import time\n",
    "import pygame\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "from datetime import datetime\n",
    "from queue import Queue\n",
    "\n",
    "class CamaraApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Detector de imágenes - Demo\")\n",
    "        self.root.config(bg=\"#2e2e2e\")\n",
    "\n",
    "        pygame.mixer.init()\n",
    "\n",
    "        self.camara_activa = False\n",
    "        self.cap = None\n",
    "        self.detectando_objetos = False\n",
    "        self.engine = pyttsx3.init()\n",
    "        self.historial_detecciones = []\n",
    "        self.objetos_para_anunciar = set()\n",
    "        self.predicciones = []\n",
    "        self.last_alert_time = 0\n",
    "        self.voz_activar = True\n",
    "        self.alarma_activar = True\n",
    "        self.camara_index = 0\n",
    "        self.voice_queue = Queue()\n",
    "        self.thread_voice = Thread(target=self.process_voice_queue)\n",
    "        self.thread_voice.daemon = True\n",
    "        self.thread_voice.start()\n",
    "\n",
    "        self.modelo_entrenado = False\n",
    "        self.entrenar_modelo_ejemplo()\n",
    "\n",
    "        self.net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]\n",
    "        self.classes = []\n",
    "        with open(\"coco.names\", \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "        self.mostrar_tutorial()\n",
    "        self.setup_ui()\n",
    "\n",
    "    def mostrar_tutorial(self):\n",
    "        tutorial_window = tk.Toplevel(self.root)\n",
    "        tutorial_window.title(\"Tutorial\")\n",
    "        tutorial_window.geometry(\"500x400\")\n",
    "        tutorial_window.config(bg=\"#1a1a1a\")\n",
    "\n",
    "        titulo = tk.Label(tutorial_window, text=\"Bienvenido al Detector de Imágenes\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 16))\n",
    "        titulo.pack(pady=10)\n",
    "\n",
    "        tutorial_text = (\n",
    "            \"Esta herramienta permite detectar objetos peligrosos en tiempo real.\\n\\n\"\n",
    "            \"1. Abre la cámara.\\n\"\n",
    "            \"2. Activa la detección de objetos.\\n\"\n",
    "            \"3. Recibe alertas por voz y visuales.\\n\"\n",
    "            \"4. Cierra la cámara cuando termines.\"\n",
    "        )\n",
    "        instrucciones = tk.Label(tutorial_window, text=tutorial_text, bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        instrucciones.pack(pady=20)\n",
    "\n",
    "        boton_omitir = tk.Button(tutorial_window, text=\"Cerrar Tutorial\", command=tutorial_window.destroy, bg=\"#4CAF50\", fg=\"white\")\n",
    "        boton_omitir.pack(pady=10)\n",
    "\n",
    "        tutorial_window.protocol(\"WM_DELETE_WINDOW\", tutorial_window.destroy)\n",
    "\n",
    "    def setup_ui(self):\n",
    "        self.frame_principal = tk.Frame(self.root, bg=\"#2e2e2e\")\n",
    "        self.frame_principal.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.frame_video = tk.Frame(self.frame_principal, bg=\"#2e2e2e\")\n",
    "        self.frame_video.pack(side=tk.LEFT, padx=10, pady=10)\n",
    "\n",
    "        self.cargar_logo()\n",
    "\n",
    "        self.frame_historial = Frame(self.frame_principal)\n",
    "        self.frame_historial.pack(side=tk.RIGHT, fill=tk.Y, padx=10, pady=10)\n",
    "\n",
    "        self.scrollbar = Scrollbar(self.frame_historial)\n",
    "        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "\n",
    "        self.label_historial_titulo = tk.Label(self.frame_historial, text=\"Historial\", bg=\"#2e2e2e\",\n",
    "                                               fg=\"white\", font=(\"Arial\", 14, \"bold\"))\n",
    "        self.label_historial_titulo.pack(pady=10)\n",
    "\n",
    "        self.text_historial = tk.Text(self.frame_historial, bg=\"#2e2e2e\", fg=\"white\", font=(\"Arial\", 12),\n",
    "                                       wrap=\"word\", height=20, width=40)\n",
    "        self.text_historial.pack(fill=tk.BOTH, expand=True, padx=10)\n",
    "        self.text_historial.config(yscrollcommand=self.scrollbar.set)\n",
    "        self.scrollbar.config(command=self.text_historial.yview)\n",
    "\n",
    "        self.canvas = tk.Canvas(self.frame_video, width=640, height=480)\n",
    "        self.canvas.pack()\n",
    "\n",
    "        self.frame_botones = tk.Frame(self.frame_video, bg=\"#3c3c3c\")\n",
    "        self.frame_botones.pack(pady=10, padx=10, fill=tk.X)\n",
    "\n",
    "        self.boton_abrir = tk.Button(self.frame_botones, text=\"Abrir Cámara\", command=self.abrir_camara, width=20,\n",
    "                                     bg=\"#4CAF50\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_abrir.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cerrar = tk.Button(self.frame_botones, text=\"Cerrar Cámara\", command=self.cerrar_camara, width=20,\n",
    "                                      state=tk.DISABLED, bg=\"#F44336\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cerrar.grid(row=0, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_deteccion = tk.Button(self.frame_botones, text=\"Detectar Objetos\", command=self.toggle_deteccion,\n",
    "                                         width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_deteccion.grid(row=1, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_voz = tk.Button(self.frame_botones, text=\"Activar Voz\", command=self.toggle_voz,\n",
    "                                   width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_voz.grid(row=1, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_alarma = tk.Button(self.frame_botones, text=\"Activar Alarma\", command=self.toggle_alarma,\n",
    "                                      width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_alarma.grid(row=2, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_descargar = tk.Button(self.frame_botones, text=\"Guardar Historial\", command=self.descargar_historial,\n",
    "                                          width=20, state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_descargar.grid(row=2, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_cambiar_camara = tk.Button(self.frame_botones, text=\"Cambiar Cámara\", command=self.cambiar_camara, width=20,\n",
    "                                              state=tk.DISABLED, bg=\"#9C27B0\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_cambiar_camara.grid(row=3, column=0, padx=10, pady=10)\n",
    "\n",
    "        self.boton_prediccion = tk.Button(self.frame_botones, text=\"Realizar Predicción\", command=self.mostrar_prediccion,\n",
    "                                           width=20, state=tk.DISABLED, bg=\"#009688\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_prediccion.grid(row=3, column=1, padx=10, pady=10)\n",
    "\n",
    "        self.boton_salir = tk.Button(self.frame_botones, text=\"Salir\", command=self.salir, width=20,\n",
    "                                     bg=\"#9E9E9E\", fg=\"white\", font=(\"Arial\", 12))\n",
    "        self.boton_salir.grid(row=4, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "    def cargar_logo(self):\n",
    "        try:\n",
    "            logo_path = \"Logo1.png\"\n",
    "            if os.path.exists(logo_path):\n",
    "                self.logo_imagen = Image.open(logo_path).resize((300, 100), Image.Resampling.LANCZOS)\n",
    "                self.logo_imagen_tk = ImageTk.PhotoImage(self.logo_imagen)\n",
    "                self.label_logo = tk.Label(self.frame_video, image=self.logo_imagen_tk, bg=\"#2e2e2e\")\n",
    "                self.label_logo.pack(pady=20)\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar la imagen: {e}\")\n",
    "\n",
    "    def hablar(self, mensaje):\n",
    "        if self.voz_activar:  # Solo agregar a la cola si la voz está activada\n",
    "            self.voice_queue.put(mensaje)\n",
    "\n",
    "    def process_voice_queue(self):\n",
    "        while True:\n",
    "            mensaje = self.voice_queue.get()\n",
    "            if self.voz_activar:  # Verificar si la voz está activada\n",
    "                self.engine.say(mensaje)\n",
    "                self.engine.runAndWait()\n",
    "\n",
    "    def entrenar_modelo_ejemplo(self):\n",
    "        X = np.array([[0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 1, 0], [0, 0, 0]])\n",
    "        y = np.array(['bajo', 'alto', 'medio', 'alto', 'bajo'])\n",
    "        \n",
    "        self.le = LabelEncoder()\n",
    "        y_encoded = self.le.fit_transform(y)\n",
    "        \n",
    "        self.modelo = MLPClassifier(hidden_layer_sizes=(10, 5), max_iter=5000, learning_rate_init=0.01)\n",
    "        self.modelo.fit(X, y_encoded)\n",
    "        self.modelo_entrenado = True\n",
    "\n",
    "    def predecir_peligro(self, datos):\n",
    "        if self.modelo_entrenado:\n",
    "            prediccion_encoded = self.modelo.predict([datos])\n",
    "            return self.le.inverse_transform(prediccion_encoded)[0]\n",
    "        return \"Error en el modelo\"\n",
    "\n",
    "    def generar_datos_prediccion(self):\n",
    "        if len(self.predicciones) == 0:\n",
    "            return [0, 0, 0]\n",
    "        \n",
    "        # Contar solo los objetos peligrosos detectados en la cámara\n",
    "        peligrosos = sum(1 for obj in self.predicciones if obj['label'] in [\"knife\", \"pistol\", \"scissors\", \"baseball bat\", \"bottle\", \"fire hydrant\", \"fork\", \"tennis racket\", \"umbrella\"])\n",
    "        no_peligrosos = len(self.predicciones) - peligrosos\n",
    "        return [peligrosos, no_peligrosos, random.randint(0, 1)]\n",
    "\n",
    "    def mostrar_prediccion(self):\n",
    "        self.ventana_prediccion = tk.Toplevel(self.root)\n",
    "        self.ventana_prediccion.title(\"Análisis de Riesgo\")\n",
    "        self.ventana_prediccion.geometry(\"400x300\")\n",
    "        self.ventana_prediccion.config(bg=\"#1a1a1a\")\n",
    "\n",
    "        titulo = tk.Label(self.ventana_prediccion, text=\"Análisis de Riesgo en Tiempo Real\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 16))\n",
    "        titulo.pack(pady=10)\n",
    "\n",
    "        self.label_resultado = tk.Label(self.ventana_prediccion, text=\"\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 14))\n",
    "        self.label_resultado.pack(pady=10)\n",
    "\n",
    "        self.label_peligrosos = tk.Label(self.ventana_prediccion, text=\"Objetos Peligrosos: 0\", bg=\"#1a1a1a\", fg=\"red\", font=(\"Arial\", 12))\n",
    "        self.label_peligrosos.pack(pady=5)\n",
    "\n",
    "        self.label_seguros = tk.Label(self.ventana_prediccion, text=\"Objetos Seguros: 0\", bg=\"#1a1a1a\", fg=\"green\", font=(\"Arial\", 12))\n",
    "        self.label_seguros.pack(pady=5)\n",
    "\n",
    "        self.label_nivel_riesgo = tk.Label(self.ventana_prediccion, text=\"Nivel de riesgo: BAJO\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 14))\n",
    "        self.label_nivel_riesgo.pack(pady=20)\n",
    "\n",
    "        nota = tk.Label(self.ventana_prediccion, text=\"* Basado en análisis de objetos detectados y patrones históricos\", bg=\"#1a1a1a\", fg=\"white\", font=(\"Arial\", 10))\n",
    "        nota.pack(pady=5)\n",
    "\n",
    "        self.thread_actualizar_prediccion = Thread(target=self.actualizar_prediccion_en_ventana)\n",
    "        self.thread_actualizar_prediccion.daemon = True\n",
    "        self.thread_actualizar_prediccion.start()\n",
    "\n",
    "    def actualizar_prediccion_en_ventana(self):\n",
    "        while self.camara_activa and self.detectando_objetos:\n",
    "            datos_entrada = self.generar_datos_prediccion()\n",
    "            resultado = self.predecir_peligro(datos_entrada)\n",
    "\n",
    "            # Verificar si la ventana aún está abierta\n",
    "            if not self.ventana_prediccion.winfo_exists():\n",
    "                break\n",
    "\n",
    "            # Contar objetos peligrosos y seguros\n",
    "            peligrosos = datos_entrada[0]\n",
    "            no_peligrosos = datos_entrada[1]\n",
    "\n",
    "            self.label_resultado.config(text=f\"Datos analizados: {resultado}\")\n",
    "            self.label_peligrosos.config(text=f\"Objetos Peligrosos: {peligrosos}\")\n",
    "            self.label_seguros.config(text=f\"Objetos Seguros: {no_peligrosos}\")\n",
    "\n",
    "            if resultado == \"alto\":\n",
    "                self.label_nivel_riesgo.config(text=\"Nivel de riesgo: ALTO\")\n",
    "            else:\n",
    "                self.label_nivel_riesgo.config(text=\"Nivel de riesgo: BAJO\")\n",
    "\n",
    "            time.sleep(1)\n",
    "\n",
    "    def abrir_camara(self):\n",
    "        if not self.camara_activa:\n",
    "            self.cap = cv2.VideoCapture(self.camara_index)\n",
    "            if not self.cap.isOpened():\n",
    "                messagebox.showerror(\"Error\", \"No se pudo abrir la cámara.\")\n",
    "                return\n",
    "\n",
    "            self.camara_activa = True\n",
    "            self.boton_abrir.config(state=tk.DISABLED)\n",
    "            self.boton_cerrar.config(state=tk.NORMAL)\n",
    "            self.boton_deteccion.config(state=tk.NORMAL)\n",
    "            self.boton_voz.config(state=tk.NORMAL)\n",
    "            self.boton_alarma.config(state=tk.NORMAL)\n",
    "            self.boton_descargar.config(state=tk.NORMAL)\n",
    "            self.boton_cambiar_camara.config(state=tk.NORMAL)\n",
    "            self.boton_prediccion.config(state=tk.NORMAL)\n",
    "\n",
    "            self.agregar_historial(\"Cámara abierta\")\n",
    "\n",
    "            self.thread_video = Thread(target=self.actualizar_video)\n",
    "            self.thread_video.daemon = True\n",
    "            self.thread_video.start()\n",
    "\n",
    "    def actualizar_video(self):\n",
    "        while self.camara_activa:\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if self.detectando_objetos:\n",
    "                self.procesar_frame(frame)\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_pil = Image.fromarray(frame_rgb)\n",
    "            frame_tk = ImageTk.PhotoImage(frame_pil)\n",
    "            self.canvas.create_image(0, 0, anchor=tk.NW, image=frame_tk)\n",
    "            self.canvas.image = frame_tk\n",
    "\n",
    "    def procesar_frame(self, frame):\n",
    "        blob = cv2.dnn.blobFromImage(frame, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        outs = self.net.forward(self.output_layers)\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.6:\n",
    "                    center_x = int(detection[0] * frame.shape[1])\n",
    "                    center_y = int(detection[1] * frame.shape[0])\n",
    "                    w = int(detection[2] * frame.shape[1])\n",
    "                    h = int(detection[3] * frame.shape[0])\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.6, 0.4)\n",
    "\n",
    "        objetos_detectados = []\n",
    "        for i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(self.classes[class_ids[i]])\n",
    "            confidence = confidences[i] * 100\n",
    "            objetos_detectados.append({'label': label, 'confidence': confidence})\n",
    "            color = (0, 255, 0)\n",
    "            if label in [\"knife\", \"pistol\", \"scissors\", \"baseball bat\", \"bottle\", \"fire hydrant\", \"fork\", \"tennis racket\", \"umbrella\"]:\n",
    "                color = (255, 0, 0)\n",
    "                self.reproducir_alerta()  # Llamar a la función de alerta\n",
    "\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(frame, f\"{label} {confidence:.2f}%\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "            # Anunciar el objeto detectado\n",
    "            if self.voz_activar and label not in self.objetos_para_anunciar:\n",
    "                self.hablar(f\"Detectado: {label}\")\n",
    "                self.objetos_para_anunciar.add(label)\n",
    "\n",
    "        self.predicciones = objetos_detectados\n",
    "        self.agregar_historial(f\"Objetos detectados: {', '.join([obj['label'] for obj in objetos_detectados])}\")\n",
    "\n",
    "    def reproducir_alerta(self):\n",
    "        if self.alarma_activar:\n",
    "            pygame.mixer.music.load(\"alerta.mp3\")  # Asegúrate de tener un archivo de sonido llamado alerta.mp3\n",
    "            pygame.mixer.music.play()\n",
    "\n",
    "    def cerrar_camara(self):\n",
    "        if self.camara_activa:\n",
    "            self.camara_activa = False\n",
    "            \n",
    "            if self.cap is not None:\n",
    "                self.cap.release()\n",
    "            \n",
    "            self.boton_abrir.config(state=tk.NORMAL)\n",
    "            self.boton_cerrar.config(state=tk.DISABLED)\n",
    "            self.boton_deteccion.config(state=tk.DISABLED)\n",
    "            self.boton_voz.config(state=tk.DISABLED)\n",
    "            self.boton_alarma.config(state=tk.DISABLED)\n",
    "            self.boton_descargar.config(state=tk.DISABLED)\n",
    "            self.boton_cambiar_camara.config(state=tk.DISABLED)\n",
    "\n",
    "            self.agregar_historial(\"Cámara cerrada\")\n",
    "\n",
    "    def cambiar_camara(self):\n",
    "        self.camara_index = 1 if self.camara_index == 0 else 0\n",
    "        self.cerrar_camara()\n",
    "        self.abrir_camara()\n",
    "        self.agregar_historial(f\"Cámara cambiada a {'Cámara web externa' if self.camara_index == 0 else 'Cámara de la laptop'}\")\n",
    "\n",
    "    def agregar_historial(self, mensaje):\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        self.historial_detecciones.append(f\"{timestamp}: {mensaje}\")\n",
    "        self.text_historial.config(state=tk.NORMAL)\n",
    "        self.text_historial.insert(tk.END, f\"{timestamp}: {mensaje}\\n\")\n",
    "        self.text_historial.config(state=tk.DISABLED)\n",
    "\n",
    "    def toggle_deteccion(self):\n",
    "        self.detectando_objetos = not self.detectando_objetos\n",
    "        estado = \"activada\" if self.detectando_objetos else \"desactivada\"\n",
    "        self.agregar_historial(f\"Detección de objetos {estado}\")\n",
    "\n",
    "        # Detener la voz si se desactiva la detección\n",
    "        if not self.detectando_objetos and self.voz_activar:\n",
    "            self.engine.stop()\n",
    "            self.objetos_para_anunciar.clear()\n",
    "\n",
    "    def toggle_voz(self):\n",
    "        self.voz_activar = not self.voz_activar\n",
    "        estado = \"activada\" if self.voz_activar else \"desactivada\"\n",
    "        self.agregar_historial(f\"Voz {estado}\")\n",
    "\n",
    "        # Cambiar el texto del botón\n",
    "        self.boton_voz.config(text=\"Desactivar Voz\" if self.voz_activar else \"Activar Voz\")\n",
    "\n",
    "    def toggle_alarma(self):\n",
    "        self.alarma_activar = not self.alarma_activar\n",
    "        estado = \"activada\" if self.alarma_activar else \"desactivada\"\n",
    "        self.agregar_historial(f\"Alarma {estado}\")\n",
    "\n",
    "    def descargar_historial(self):\n",
    "        if self.historial_detecciones:\n",
    "            archivo = filedialog.asksaveasfilename(defaultextension=\".txt\",\n",
    "                                                    filetypes=[(\"Archivos de texto\", \"*.txt\")])\n",
    "            if archivo:\n",
    "                with open(archivo, \"w\") as f:\n",
    "                    for mensaje in self.historial_detecciones:\n",
    "                        f.write(mensaje + \"\\n\")\n",
    "                messagebox.showinfo(\"Descargar Historial\", \"Historial guardado correctamente.\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"Descargar Historial\", \"No hay historial para guardar.\")\n",
    "\n",
    "    def salir(self):\n",
    "        self.cerrar_camara()\n",
    "        self.root.quit()\n",
    "\n",
    "# Crear ventana principal\n",
    "root = tk.Tk()\n",
    "root.geometry(\"1500x1100\")\n",
    "root.resizable(False, False)\n",
    "app = CamaraApp(root)\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
